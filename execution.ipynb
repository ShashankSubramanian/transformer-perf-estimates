{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3876fb2-fec7-43b1-a65a-531fb1e6cedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.lines import Line2D\n",
    "import pprint\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "from modules import *\n",
    "from execution import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2b0c4-dd59-453b-bd85-fa200178727c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt2 = {'l': 1024, 'e': 1600, 'h': 32, 'depth': 48}\n",
    "gpt3_xl = {'l': 2048, 'e': 2048, 'h': 16, 'depth': 24}\n",
    "gpt3 = {'l': 2048, 'e': 12288, 'h': 96, 'depth': 96}\n",
    "gpt3_1T = {'l': 2048, 'e': 25600, 'h': 160, 'depth': 128}\n",
    "gpt3_1T_fut = {'l': 2048, 'e': 25600, 'h': 160, 'depth': 128*3}\n",
    "gpt3_1T_alt = {'l': 2048, 'e': 32768, 'h': 128, 'depth': 128}\n",
    "gpt3_1T_alt_fut = {'l': 2048, 'e': 32768, 'h': 128, 'depth': 128*3}\n",
    "gpt3_lowdepth = {'l': 2048, 'e': 12288, 'h': 256, 'depth': 96 // 8}\n",
    "vit_era5 = {'l': 64800*4, 'e': 4096, 'h': 32, 'depth': 32}\n",
    "vit_era5_v2 = {'l': 64800, 'e': 4096, 'h': 32, 'depth': 32}\n",
    "vit_era5_big = {'l': 64800*4, 'e': 12288, 'h': 128, 'depth': 64}\n",
    "### model\n",
    "model = gpt3_1T\n",
    "model_str = 'gpt3_1T'\n",
    "l = model['l']\n",
    "e = model['e']\n",
    "f = 4 * e\n",
    "model['f'] = f\n",
    "h = model['h']\n",
    "depth = model['depth']\n",
    "print(model)\n",
    "\n",
    "# two sizes: 300B and 10T for NLP\n",
    "total_tokens = 300 * 10**12\n",
    "num_samples = total_tokens / l\n",
    "print(total_tokens, l, num_samples)\n",
    "\n",
    "# for era5\n",
    "# num_ep = 500\n",
    "# num_samples = 250000 * num_ep\n",
    "# print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b197343-1f2b-488c-b40b-49003da511da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_gpus = [2048]\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('systems/config-B200.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "system['nvlink_size'] = 4\n",
    "\n",
    "configs = execute_1d(model, n_gpus, global_batch_size=global_batch_size, \n",
    "                     system=system, verbose=False, nlargest=2)\n",
    "pprint.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8e42f-cfc9-4d9a-8879-412cbe83bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 4096\n",
    "systems = ['A100-NVL4', 'B200-NVL2', 'B200-NVL8', 'B200-next-NVL2', 'B200-next-NVL8']\n",
    "config_names = ['A100', 'B200', 'B200', 'B200-next', 'B200-next']\n",
    "nvlink_sizes = [4, 2, 8, 2, 8]\n",
    "           \n",
    "for sidx, sys_str in enumerate(systems):\n",
    "    with open('systems/config-' + config_names[sidx] + '.json', 'r') as file:\n",
    "        system = json.load(file)\n",
    "\n",
    "    # nvs_list = [2, 8, 32, 128]\n",
    "    nvs_list = [nvlink_sizes[sidx]]\n",
    "    print(sys_str, nvs_list)\n",
    "    verbose = False\n",
    "    plots = []\n",
    "\n",
    "    for nvs in nvs_list:\n",
    "        t = []\n",
    "        conf = []\n",
    "        start = None\n",
    "        system['nvlink_size'] = nvs\n",
    "        n_gpus = 2**np.array([i for i in range(2,15)])\n",
    "        configs = execute_1d(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=10)\n",
    "        for s,config in enumerate(configs):\n",
    "            if len(config) > 0: # check feasibility\n",
    "                if not start and start != 0:\n",
    "                    start = s\n",
    "                conf.append(config)\n",
    "                t.append([c[0] for c in config])\n",
    "        # print(t)\n",
    "\n",
    "        t_max = [tm[0] for tm in t]\n",
    "        t_min = [tm[-1] for tm in t]\n",
    "        n_gpus = n_gpus[start:]\n",
    "        configs = configs[start:]\n",
    "\n",
    "        plots.append((nvs, t_max, t_min, n_gpus, configs))\n",
    "    np.save('outputs/exec_1d_{}_{}.npy'.format(model_str, sys_str), np.array(plots, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031f899-9d3c-4c5c-b982-ec5282a12380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "systems = ['A100-NVL4', 'B200-NVL2', 'B200-NVL8', 'B200-next-NVL2', 'B200-next-NVL8']\n",
    "styles = ['<', 'o', 'x', '^', 's', 'D']\n",
    "st_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2']\n",
    "\n",
    "# Create figure and axis\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 8), tight_layout=True)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "# Initialize legend handles\n",
    "sys_str_handles = []\n",
    "\n",
    "for st, sys_str in enumerate(systems):\n",
    "    x = np.load('outputs/exec_1d_{}_{}.npy'.format(model_str, sys_str), allow_pickle=True)\n",
    "    nvc = 0\n",
    "    for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "        print(sys_str, nvs)\n",
    "        if len(t_max) == 0:\n",
    "            continue\n",
    "        time = [(num_samples / tm) / (3600 * 24) for tm in t_max]\n",
    "        # print(time)\n",
    "        line, = axs.plot(n_gpus, time, label=f'nv = {nvs}', marker=styles[st], markersize=9, color=st_colors[st], linewidth=2)\n",
    "        # axs.fill_between(n_gpus, t_max, t_min, color=st_colors[st], alpha=0.2)\n",
    "        axs.set_yscale('log', base=10)\n",
    "        axs.set_xscale('log', base=2)\n",
    "        axs.set_xticks(n_gpus)\n",
    "        axs.set_xticklabels(n_gpus)\n",
    "        axs.set_xlabel('Number of GPUs', fontsize=16)\n",
    "        axs.set_ylabel('Training Time (Days)', fontsize=16)\n",
    "        # axs.set_yticks(10. ** np.arange(1, 3))\n",
    "        # axs.set_ylim([5,5000])\n",
    "        nvc += 1\n",
    "    sys_str_handles.append(Line2D([0], [0], marker=styles[st], color=st_colors[st], label=sys_str, linestyle='None', markersize=10))\n",
    "\n",
    "# Add legends\n",
    "# nv_legend = axs.legend(handles=nv_handles, title=\"NVLink Size\", fontsize=14, loc='upper left', title_fontsize=16)\n",
    "sys_str_legend = axs.legend(handles=sys_str_handles, title=\"Systems\", fontsize=14, loc='upper right', title_fontsize=16)\n",
    "# axs.add_artist(nv_legend)\n",
    "\n",
    "# Additional aesthetics\n",
    "axs.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "axs.set_title('Performance Comparison Across Systems', fontsize=18, pad=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('outputs/exec_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b9d89-f697-4eba-9c55-a8d994ac9304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "styles = ['<', 'o', 'x']\n",
    "nv_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Better color palette\n",
    "\n",
    "# Create figure and axis\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 8), tight_layout=True)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "# Initialize legend handles\n",
    "nv_handles = []\n",
    "sys_str_handles = []\n",
    "\n",
    "for st, sys_str in enumerate(systems):\n",
    "    x = np.load('outputs/exec_1d_{}_{}.npy'.format(model_str, sys_str), allow_pickle=True)\n",
    "    nvc = 0\n",
    "    for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "        if len(t_max) == 0:\n",
    "            continue\n",
    "        line, = axs.plot(n_gpus, t_max, label=f'nv = {nvs}', marker=styles[st], markersize=9, color=nv_colors[nvc], linewidth=2)\n",
    "        if len(nv_handles) < 4:\n",
    "            nv_handles.append(Line2D([0], [0], marker='o', color='w', label=f'NVS = {nvs}', markerfacecolor=nv_colors[nvc], markersize=10))\n",
    "        axs.fill_between(n_gpus, t_max, t_min, color=nv_colors[nvc], alpha=0.2)\n",
    "        axs.set_yscale('log', base=2)\n",
    "        axs.set_xscale('log', base=2)\n",
    "        axs.set_xticks(n_gpus)\n",
    "        axs.set_xticklabels(n_gpus)\n",
    "        axs.set_xlabel('Number of GPUs', fontsize=16)\n",
    "        axs.set_ylabel('Throughput (inputs/sec)', fontsize=16)\n",
    "        axs.set_yticks(2. ** np.arange(-1, 10))\n",
    "        nvc += 1\n",
    "    sys_str_handles.append(Line2D([0], [0], marker=styles[st], color='k', label=sys_str, linestyle='None', markersize=10))\n",
    "\n",
    "# Add legends\n",
    "nv_legend = axs.legend(handles=nv_handles, title=\"NVLink Size\", fontsize=14, loc='upper left', title_fontsize=16)\n",
    "sys_str_legend = axs.legend(handles=sys_str_handles, title=\"Systems\", fontsize=14, loc='upper right', title_fontsize=16)\n",
    "axs.add_artist(nv_legend)\n",
    "\n",
    "# Additional aesthetics\n",
    "axs.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "axs.set_title('Performance Comparison Across Systems', fontsize=18, pad=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('outputs/exec_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c4ddc-633b-41f4-aa32-87dee81503de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(5,5), tight_layout=True) \n",
    "\n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "    axs.plot(n_gpus, t_max, label='nv = {}'.format(nvs))\n",
    "    axs.fill_between(n_gpus, t_max, t_min, alpha=0.25)\n",
    "    # print(np.array(t_max) - np.array(t_min))\n",
    "    axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Throughput (inputs/sec)', fontsize=14)\n",
    "    axs.set_yticks(2.**np.arange(-2,7))\n",
    "axs.legend(fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.savefig('outputs/exec_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634a963-623b-432e-9d3c-7437772b5536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_clustered_stacked(dfall, labels=None, title=\"multiple stacked bar plot\",  H=\"/\", **kwargs):\n",
    "    \"\"\"Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot. \n",
    "labels is a list of the names of the dataframe, used for the legend\n",
    "title is a string for the title of the plot\n",
    "H is the hatch used for identification of the different dataframe\"\"\"\n",
    "\n",
    "    n_df = len(dfall)\n",
    "    n_col = len(dfall[0].columns) \n",
    "    n_ind = len(dfall[0].index)\n",
    "    # axe = plt.subplot(111)\n",
    "    fig, axe = plt.subplots(1,1,figsize=(8,8)) \n",
    "\n",
    "    for df in dfall : # for each data frame\n",
    "        axe = df.plot(kind=\"bar\",\n",
    "                      linewidth=0,\n",
    "                      stacked=True,\n",
    "                      ax=axe,\n",
    "                      legend=False,\n",
    "                      grid=False,\n",
    "                      fontsize=15,\n",
    "                      **kwargs)  # make bar plots\n",
    "        for c in axe.containers:\n",
    "            # Optional: if the segment is small or 0, customize the labels\n",
    "            labels_interior = [str(int(v.get_height())) if v.get_height() > 0 else '' for v in c]\n",
    "            # remove the labels parameter if it's not needed for customized labels\n",
    "            axe.bar_label(c, labels=labels_interior, label_type='center', \n",
    "                          weight='bold', style='italic', family='serif', rotation=90)\n",
    "\n",
    "    h,l = axe.get_legend_handles_labels() # get the handles we want to modify\n",
    "    for i in range(0, n_df * n_col, n_col): # len(h) = n_col * n_df\n",
    "        for j, pa in enumerate(h[i:i+n_col]):\n",
    "            for rect in pa.patches: # for each index\n",
    "                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))\n",
    "                rect.set_hatch(H * int(i / n_col)) #edited part     \n",
    "                rect.set_width(1 / float(n_df + 1))\n",
    "\n",
    "    axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.)\n",
    "    axe.set_xticklabels(df.index, rotation = 0)\n",
    "    axe.set_title(title)\n",
    "\n",
    "    # Add invisible data to add another legend\n",
    "    n=[]        \n",
    "    for i in range(n_df):\n",
    "        n.append(axe.bar(0, 0, color=\"gray\", hatch=H * i))\n",
    "\n",
    "    l1 = axe.legend(h[:n_col], l[:n_col])\n",
    "    if labels is not None:\n",
    "        l2 = plt.legend(n, labels, loc=[0.2, 0.85]) \n",
    "    axe.add_artist(l1)\n",
    "    return axe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76531d17-0d62-4991-8467-6f0ebdab0b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}_Bnext-AI-NVL2.npy'.format(model_str), allow_pickle=True)\n",
    "dfs = []\n",
    "nvs_str = []\n",
    "for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "    best_configs = [c[0][2] for c in configs]\n",
    "    n_gpus_str = [str(ng) for ng in n_gpus]\n",
    "    parallelization = {\n",
    "        # 'data': np.array([c['dp'] for c in best_configs]),\n",
    "        'tensor': np.array([c['tp'] for c in best_configs]),\n",
    "        'pipeline': np.array([c['pp'] for c in best_configs])\n",
    "    }\n",
    "    data = np.zeros((len(n_gpus),2))\n",
    "    idx=-1\n",
    "    # data[:,idx] = np.array([c['dp'] for c in best_configs])\n",
    "    data[:,idx+1] = np.array([c['tp'] for c in best_configs])\n",
    "    data[:,idx+2] = np.array([c['pp'] for c in best_configs])\n",
    "    df = pd.DataFrame(data,\n",
    "                   index=n_gpus_str,\n",
    "                   columns=[\"tensor\", \"pipeline\"])\n",
    "    dfs.append(df)\n",
    "    nvs_str.append(\"nvs = \" + str(nvs))\n",
    "plot_clustered_stacked(dfs, nvs_str, cmap='Pastel2', title='Parallelization configs')\n",
    "# plt.savefig('outputs/par_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9452b-75dd-4455-a2a3-bcef8138e3d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_gpus = 2**np.array([i for i in range(2,14)])\n",
    "n_gpus = [2048]\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('systems/config-A100.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "system['nvlink_size'] = 4\n",
    "\n",
    "configs = execute_2d(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=1)\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b0b34-acf1-45ae-a64e-782cad4a4171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_size = 4096\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "\n",
    "nvs_list = [2, 4, 16, 32]\n",
    "verbose = False\n",
    "plots = []\n",
    "\n",
    "for nvs in nvs_list:\n",
    "    t = []\n",
    "    conf = []\n",
    "    start = None\n",
    "    system['nvlink_size'] = nvs\n",
    "    n_gpus = 2**np.array([i for i in range(2,14)])\n",
    "    configs = execute_2d(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=10)\n",
    "    for s,config in enumerate(configs):\n",
    "        if len(config) > 0: # check feasibility\n",
    "            if not start:\n",
    "                start = s\n",
    "            conf.append(config)\n",
    "            t.append([c[0] for c in config])\n",
    "    # print(t)\n",
    "\n",
    "    t_max = [tm[0] for tm in t]\n",
    "    t_min = [tm[-1] for tm in t]\n",
    "    n_gpus = n_gpus[start:]\n",
    "    configs = configs[start:]\n",
    "    \n",
    "    plots.append((nvs, t_max, t_min, n_gpus, configs))\n",
    "np.save('outputs/exec_2d_{}.npy'.format(model_str), np.array(plots, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6736b77-3225-4b04-864e-686672fbb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = ['<', 'o', 'x']\n",
    "nv_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Better color palette\n",
    "\n",
    "# Create figure and axis\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 8), tight_layout=True)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "# Initialize legend handles\n",
    "nv_handles = []\n",
    "sys_str_handles = []\n",
    "\n",
    "systems = ['A100', 'Bnext-CO', 'Bnext-AI']\n",
    "for st, sys_str in enumerate(systems):\n",
    "    x = np.load('outputs/exec_2d_{}_{}.npy'.format(model_str, sys_str), allow_pickle=True)\n",
    "    nvc = 0\n",
    "    for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "        line, = axs.plot(n_gpus, t_max, label=f'nv = {nvs}', marker=styles[st], markersize=9, color=nv_colors[nvc], linewidth=2)\n",
    "        if st == 0:\n",
    "            nv_handles.append(Line2D([0], [0], marker='o', color='w', label=f'NVS = {nvs}', markerfacecolor=nv_colors[nvc], markersize=10))\n",
    "        axs.fill_between(n_gpus, t_max, t_min, color=nv_colors[nvc], alpha=0.2)\n",
    "        axs.set_yscale('log', base=2)\n",
    "        axs.set_xscale('log', base=2)\n",
    "        axs.set_xticks(n_gpus)\n",
    "        axs.set_xticklabels(n_gpus)\n",
    "        axs.set_xlabel('Number of GPUs', fontsize=16)\n",
    "        axs.set_ylabel('Throughput (inputs/sec)', fontsize=16)\n",
    "        axs.set_yticks(2. ** np.arange(-1, 10))\n",
    "        nvc += 1\n",
    "    sys_str_handles.append(Line2D([0], [0], marker=styles[st], color='k', label=sys_str, linestyle='None', markersize=10))\n",
    "\n",
    "# Add legends\n",
    "nv_legend = axs.legend(handles=nv_handles, title=\"NVLink Size\", fontsize=14, loc='upper left', title_fontsize=16)\n",
    "sys_str_legend = axs.legend(handles=sys_str_handles, title=\"Systems\", fontsize=14, loc='upper right', title_fontsize=16)\n",
    "axs.add_artist(nv_legend)\n",
    "\n",
    "# Additional aesthetics\n",
    "axs.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "axs.set_title('Performance Comparison Across Systems', fontsize=18, pad=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0905afdc-d1ca-40f1-a3b5-4ae423aa5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_2d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(5,5), tight_layout=True) \n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "for nvs, t_max, t_min, n_gpus, _ in x:\n",
    "    axs.plot(n_gpus, t_max, label='nv = {}'.format(nvs))\n",
    "    axs.fill_between(n_gpus, t_max, t_min, alpha=0.25)\n",
    "    axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Throughput (inputs/sec)', fontsize=14)\n",
    "    axs.set_yticks(2.**np.arange(-1,7))\n",
    "    # axs.set_yticklabels(2.**np.arange(-1,7))\n",
    "axs.legend(fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.savefig('outputs/exec_2d_{}.png'.format(model_str), dpi=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ace424-667c-4b76-ac51-7e0c4bccd795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_2d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "dfs = []\n",
    "nvs_str = []\n",
    "for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "    best_configs = [c[0][2] for c in configs]\n",
    "    n_gpus_str = [str(ng) for ng in n_gpus]\n",
    "    parallelization = {\n",
    "        # 'data': np.array([c['dp'] for c in best_configs]),\n",
    "        'tensor1': np.array([c['tp1'] for c in best_configs]),\n",
    "        'tensor2': np.array([c['tp2'] for c in best_configs]),\n",
    "        'pipeline': np.array([c['pp'] for c in best_configs])\n",
    "    }\n",
    "    data = np.zeros((len(n_gpus),len(parallelization)))\n",
    "    idx=-1\n",
    "    # data[:,idx] = np.array([c['dp'] for c in best_configs])\n",
    "    data[:,idx+1] = np.array([c['tp1'] for c in best_configs])\n",
    "    data[:,idx+2] = np.array([c['tp2'] for c in best_configs])\n",
    "    data[:,idx+3] = np.array([c['pp'] for c in best_configs])\n",
    "    df = pd.DataFrame(data,\n",
    "                   index=n_gpus_str,\n",
    "                   columns=[ \"tensor1\", \"tensor2\", \"pipeline\"])\n",
    "    dfs.append(df)\n",
    "    nvs_str.append(\"nvs = \" + str(nvs))\n",
    "plot_clustered_stacked(dfs, nvs_str, cmap='Pastel2', title='Parallelization configs')\n",
    "plt.savefig('outputs/par_2d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a120c-da13-47f8-aa8d-4ada3c3b4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = [2048]\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('systems/config-A100.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "system['nvlink_size'] = 4\n",
    "\n",
    "configs = execute_seqp(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=5)\n",
    "pprint.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8531f0-ea32-47b4-a561-8e74b12a5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 4096\n",
    "systems = ['A100-NVL4', 'B200-NVL2', 'B200-NVL8', 'B200-next-NVL2', 'B200-next-NVL8']\n",
    "config_names = ['A100', 'B200', 'B200', 'B200-next', 'B200-next']\n",
    "nvlink_sizes = [4, 2, 8, 2, 8]\n",
    "           \n",
    "for sidx, sys_str in enumerate(systems):\n",
    "    with open('config-' + config_names[sidx] + '.json', 'r') as file:\n",
    "        system = json.load(file)\n",
    "\n",
    "    # nvs_list = [2, 8, 32, 128]\n",
    "    nvs_list = [nvlink_sizes[sidx]]\n",
    "    print(sys_str, nvs_list)\n",
    "    verbose = False\n",
    "    plots = []\n",
    "\n",
    "    for nvs in nvs_list:\n",
    "        t = []\n",
    "        conf = []\n",
    "        start = None\n",
    "        system['nvlink_size'] = nvs\n",
    "        n_gpus = 2**np.array([i for i in range(2,15)])\n",
    "        configs = execute_seqp(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=10)\n",
    "        for s,config in enumerate(configs):\n",
    "            if len(config) > 0: # check feasibility\n",
    "                if not start and start != 0:\n",
    "                    start = s\n",
    "                conf.append(config)\n",
    "                t.append([c[0] for c in config])\n",
    "        # print(t)\n",
    "\n",
    "        t_max = [tm[0] for tm in t]\n",
    "        t_min = [tm[-1] for tm in t]\n",
    "        n_gpus = n_gpus[start:]\n",
    "        configs = configs[start:]\n",
    "\n",
    "        plots.append((nvs, t_max, t_min, n_gpus, configs))\n",
    "    np.save('outputs/exec_seqp_{}_{}.npy'.format(model_str, sys_str), np.array(plots, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d2a34e-beac-4b10-8fe9-aab600708733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "systems = ['A100-NVL4', 'B200-NVL2', 'B200-NVL8', 'B200-next-NVL2', 'B200-next-NVL8']\n",
    "styles = ['<', 'o', 'x', '^', 's', 'D']\n",
    "st_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2']\n",
    "\n",
    "\n",
    "\n",
    "# Create figure and axis\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 8), tight_layout=True)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "# Initialize legend handles\n",
    "sys_str_handles = []\n",
    "\n",
    "for st, sys_str in enumerate(systems):\n",
    "    x = np.load('outputs/exec_seqp_{}_{}.npy'.format(model_str, sys_str), allow_pickle=True)\n",
    "    nvc = 0\n",
    "    for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "        print(sys_str, nvs)\n",
    "        if len(t_max) == 0:\n",
    "            continue\n",
    "        time = [(num_samples / tm) / (3600 * 24) for tm in t_max]\n",
    "        # print(time)\n",
    "        line, = axs.plot(n_gpus, time, label=f'nv = {nvs}', marker=styles[st], markersize=9, color=st_colors[st], linewidth=2)\n",
    "        # axs.fill_between(n_gpus, t_max, t_min, color=st_colors[st], alpha=0.2)\n",
    "        axs.set_yscale('log', base=10)\n",
    "        axs.set_xscale('log', base=2)\n",
    "        axs.set_xticks(n_gpus)\n",
    "        axs.set_xticklabels(n_gpus)\n",
    "        axs.set_xlabel('Number of GPUs', fontsize=16)\n",
    "        axs.set_ylabel('Training Time (Days)', fontsize=16)\n",
    "        # axs.set_yticks(10. ** np.arange(1, 3))\n",
    "        # axs.set_ylim([5,5000])\n",
    "        nvc += 1\n",
    "    sys_str_handles.append(Line2D([0], [0], marker=styles[st], color=st_colors[st], label=sys_str, linestyle='None', markersize=10))\n",
    "\n",
    "# Add legends\n",
    "# nv_legend = axs.legend(handles=nv_handles, title=\"NVLink Size\", fontsize=14, loc='upper left', title_fontsize=16)\n",
    "sys_str_legend = axs.legend(handles=sys_str_handles, title=\"Systems\", fontsize=14, loc='upper right', title_fontsize=16)\n",
    "# axs.add_artist(nv_legend)\n",
    "\n",
    "# Additional aesthetics\n",
    "axs.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "axs.set_title('Performance Comparison Across Systems', fontsize=18, pad=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('outputs/n10_exec_seqp_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1ae61-5eaf-48a6-866c-6f54af545b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "styles = ['<', 'o', 'x']\n",
    "nv_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Better color palette\n",
    "\n",
    "# Create figure and axis\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 8), tight_layout=True)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "# Initialize legend handles\n",
    "nv_handles = []\n",
    "sys_str_handles = []\n",
    "\n",
    "systems = ['A100', 'Bnext-CO', 'Bnext-AI']\n",
    "for st, sys_str in enumerate(systems):\n",
    "    x = np.load('outputs/exec_seqp_{}_{}.npy'.format(model_str, sys_str), allow_pickle=True)\n",
    "    nvc = 0\n",
    "    for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "        line, = axs.plot(n_gpus, t_max, label=f'nv = {nvs}', marker=styles[st], markersize=9, color=nv_colors[nvc], linewidth=2)\n",
    "        if st == 0:\n",
    "            nv_handles.append(Line2D([0], [0], marker='o', color='w', label=f'NVS = {nvs}', markerfacecolor=nv_colors[nvc], markersize=10))\n",
    "        axs.fill_between(n_gpus, t_max, t_min, color=nv_colors[nvc], alpha=0.2)\n",
    "        axs.set_yscale('log', base=2)\n",
    "        axs.set_xscale('log', base=2)\n",
    "        axs.set_xticks(n_gpus)\n",
    "        axs.set_xticklabels(n_gpus)\n",
    "        axs.set_xlabel('Number of GPUs', fontsize=16)\n",
    "        axs.set_ylabel('Throughput (inputs/sec)', fontsize=16)\n",
    "        axs.set_yticks(2. ** np.arange(-1, 10))\n",
    "        nvc += 1\n",
    "    sys_str_handles.append(Line2D([0], [0], marker=styles[st], color='k', label=sys_str, linestyle='None', markersize=10))\n",
    "\n",
    "# Add legends\n",
    "nv_legend = axs.legend(handles=nv_handles, title=\"NVLink Size\", fontsize=14, loc='upper left', title_fontsize=16)\n",
    "sys_str_legend = axs.legend(handles=sys_str_handles, title=\"Systems\", fontsize=14, loc='upper right', title_fontsize=16)\n",
    "axs.add_artist(nv_legend)\n",
    "\n",
    "# Additional aesthetics\n",
    "axs.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "axs.set_title('Performance Comparison Across Systems', fontsize=18, pad=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('outputs/exec_seqp_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080ab2d-af99-4868-9fe1-fa8429a69f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_seqp_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(5,5), tight_layout=True) \n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "for nvs, t_max, t_min, n_gpus, _ in x:\n",
    "    axs.plot(n_gpus, t_max, label='nv = {}'.format(nvs))\n",
    "    axs.fill_between(n_gpus, t_max, t_min, alpha=0.25)\n",
    "    axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Throughput (inputs/sec)', fontsize=14)\n",
    "    axs.set_yticks(2.**np.arange(1,7))\n",
    "    # axs.set_yticklabels(2.**np.arange(-1,7))\n",
    "axs.legend(fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.savefig('outputs/exec_seqp_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852185a-dbcc-4363-8834-acdbaca57563",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_seqp_{}_A100.npy'.format(model_str), allow_pickle=True)\n",
    "dfs = []\n",
    "nvs_str = []\n",
    "for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "    best_configs = [c[0][2] for c in configs]\n",
    "    n_gpus_str = [str(ng) for ng in n_gpus]\n",
    "    parallelization = {\n",
    "        # 'data': np.array([c['dp'] for c in best_configs]),\n",
    "        'tensor1': np.array([c['tp1'] for c in best_configs]),\n",
    "        'tensor2': np.array([c['tp2'] for c in best_configs]),\n",
    "        'pipeline': np.array([c['pp'] for c in best_configs])\n",
    "    }\n",
    "    data = np.zeros((len(n_gpus),len(parallelization)))\n",
    "    idx=-1\n",
    "    # data[:,idx] = np.array([c['dp'] for c in best_configs])\n",
    "    data[:,idx+1] = np.array([c['tp1'] for c in best_configs])\n",
    "    data[:,idx+2] = np.array([c['tp2'] for c in best_configs])\n",
    "    data[:,idx+3] = np.array([c['pp'] for c in best_configs])\n",
    "    df = pd.DataFrame(data,\n",
    "                   index=n_gpus_str,\n",
    "                   columns=[\"tensor1\", \"tensor2\", \"pipeline\"])\n",
    "    dfs.append(df)\n",
    "    nvs_str.append(\"nvs = \" + str(nvs))\n",
    "plot_clustered_stacked(dfs, nvs_str, cmap='Pastel2', title='Parallelization configs')\n",
    "plt.savefig('outputs/par_seqp_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67331e-d6df-4bc2-a7dc-d0dff618b435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
