{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3876fb2-fec7-43b1-a65a-531fb1e6cedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "from modules import *\n",
    "from execution import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2b0c4-dd59-453b-bd85-fa200178727c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt2 = {'l': 1024, 'e': 1600, 'h': 32, 'depth': 48}\n",
    "gpt3 = {'l': 2048, 'e': 12288, 'h': 96, 'depth': 96}\n",
    "gpt3_1T = {'l': 2048, 'e': 25600, 'h': 160, 'depth': 180}\n",
    "gpt3_lowdepth = {'l': 2048, 'e': 12288, 'h': 256, 'depth': 96 // 8}\n",
    "vit_era5 = {'l': 64800, 'e': 5120, 'h': 32, 'depth': 24}\n",
    "vit_era5_big = {'l': 64800, 'e': 6144, 'h': 32, 'depth': 32}\n",
    "vit_era5_1px = {'l': 1036800, 'e': 6144, 'h': 32, 'depth': 32}\n",
    "vit_era5_1px_big = {'l': 1036800, 'e': 12288, 'h': 96, 'depth': 96}\n",
    "### model\n",
    "model = gpt3_1T\n",
    "model_str = 'gpt3_1T'\n",
    "# model = vit_era5_1px\n",
    "l = model['l']\n",
    "e = model['e']\n",
    "f = 4 * e\n",
    "model['f'] = f\n",
    "h = model['h']\n",
    "depth = model['depth']\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975b965-53f2-41be-a7d3-947cf8963f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d334d2-483f-4b28-88f6-1118d2a34778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_df(df_mlp, df_sa):\n",
    "    cols = df_mlp.columns.tolist()\n",
    "    layer_track_cols = ['activation_buffer', 'weights_mem', \n",
    "                        'weights_grad_mem', 'flops_fwd', 'flops_bwd', \n",
    "                        't_fwd', 't_fwd_comm', 't_bwd', 't_bwd_comm']\n",
    "    display(df_mlp[cols])\n",
    "    display(df_mlp[layer_track_cols].sum())\n",
    "    display(df_sa[cols])\n",
    "    display(df_sa[layer_track_cols].sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b197343-1f2b-488c-b40b-49003da511da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_gpus = [2048]\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "system['nvlink_size'] = 4\n",
    "\n",
    "configs = execute_1d(model, n_gpus, global_batch_size=global_batch_size, \n",
    "                     system=system, verbose=False, nlargest=1)\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8e42f-cfc9-4d9a-8879-412cbe83bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 4096\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "\n",
    "nvs_list = [2, 4, 16, 32]\n",
    "verbose = False\n",
    "plots = []\n",
    "\n",
    "for nvs in nvs_list:\n",
    "    t = []\n",
    "    conf = []\n",
    "    start = None\n",
    "    system['nvlink_size'] = nvs\n",
    "    n_gpus = 2**np.array([i for i in range(2,14)])\n",
    "    configs = execute_1d(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=10)\n",
    "    for s,config in enumerate(configs):\n",
    "        if len(config) > 0: # check feasibility\n",
    "            if not start:\n",
    "                start = s\n",
    "            conf.append(config)\n",
    "            t.append([c[0] for c in config])\n",
    "    # print(t)\n",
    "\n",
    "    t_max = [tm[0] for tm in t]\n",
    "    t_min = [tm[-1] for tm in t]\n",
    "    n_gpus = n_gpus[start:]\n",
    "    configs = configs[start:]\n",
    "    \n",
    "    plots.append((nvs, t_max, t_min, n_gpus, configs))\n",
    "np.save('outputs/exec_1d_{}.npy'.format(model_str), np.array(plots, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0c4ddc-633b-41f4-aa32-87dee81503de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(5,5), tight_layout=True) \n",
    "\n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "    axs.plot(n_gpus, t_max, label='nv = {}'.format(nvs))\n",
    "    axs.fill_between(n_gpus, t_max, t_min, alpha=0.25)\n",
    "    # print(np.array(t_max) - np.array(t_min))\n",
    "    axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Throughput (inputs/sec)', fontsize=14)\n",
    "    axs.set_yticks(2.**np.arange(-1,7))\n",
    "axs.legend(fontsize=14)\n",
    "fig.tight_layout()\n",
    "# plt.savefig('outputs/exec_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634a963-623b-432e-9d3c-7437772b5536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_clustered_stacked(dfall, labels=None, title=\"multiple stacked bar plot\",  H=\"/\", **kwargs):\n",
    "    \"\"\"Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot. \n",
    "labels is a list of the names of the dataframe, used for the legend\n",
    "title is a string for the title of the plot\n",
    "H is the hatch used for identification of the different dataframe\"\"\"\n",
    "\n",
    "    n_df = len(dfall)\n",
    "    n_col = len(dfall[0].columns) \n",
    "    n_ind = len(dfall[0].index)\n",
    "    # axe = plt.subplot(111)\n",
    "    fig, axe = plt.subplots(1,1,figsize=(8,8)) \n",
    "\n",
    "    for df in dfall : # for each data frame\n",
    "        axe = df.plot(kind=\"bar\",\n",
    "                      linewidth=0,\n",
    "                      stacked=True,\n",
    "                      ax=axe,\n",
    "                      legend=False,\n",
    "                      grid=False,\n",
    "                      fontsize=15,\n",
    "                      **kwargs)  # make bar plots\n",
    "        for c in axe.containers:\n",
    "            # Optional: if the segment is small or 0, customize the labels\n",
    "            labels_interior = [str(int(v.get_height())) if v.get_height() > 0 else '' for v in c]\n",
    "            # remove the labels parameter if it's not needed for customized labels\n",
    "            axe.bar_label(c, labels=labels_interior, label_type='center', \n",
    "                          weight='bold', style='italic', family='serif', rotation=90)\n",
    "\n",
    "    h,l = axe.get_legend_handles_labels() # get the handles we want to modify\n",
    "    for i in range(0, n_df * n_col, n_col): # len(h) = n_col * n_df\n",
    "        for j, pa in enumerate(h[i:i+n_col]):\n",
    "            for rect in pa.patches: # for each index\n",
    "                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))\n",
    "                rect.set_hatch(H * int(i / n_col)) #edited part     \n",
    "                rect.set_width(1 / float(n_df + 1))\n",
    "\n",
    "    axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.)\n",
    "    axe.set_xticklabels(df.index, rotation = 0)\n",
    "    axe.set_title(title)\n",
    "\n",
    "    # Add invisible data to add another legend\n",
    "    n=[]        \n",
    "    for i in range(n_df):\n",
    "        n.append(axe.bar(0, 0, color=\"gray\", hatch=H * i))\n",
    "\n",
    "    l1 = axe.legend(h[:n_col], l[:n_col])\n",
    "    if labels is not None:\n",
    "        l2 = plt.legend(n, labels, loc=[0.2, 0.85]) \n",
    "    axe.add_artist(l1)\n",
    "    return axe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76531d17-0d62-4991-8467-6f0ebdab0b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "dfs = []\n",
    "nvs_str = []\n",
    "for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "    best_configs = [c[0][2] for c in configs]\n",
    "    n_gpus_str = [str(ng) for ng in n_gpus]\n",
    "    parallelization = {\n",
    "        'data': np.array([c['dp'] for c in best_configs]),\n",
    "        'tensor': np.array([c['tp'] for c in best_configs]),\n",
    "        'pipeline': np.array([c['pp'] for c in best_configs])\n",
    "    }\n",
    "    data = np.zeros((len(n_gpus),3))\n",
    "    data[:,0] = np.array([c['dp'] for c in best_configs])\n",
    "    data[:,1] = np.array([c['tp'] for c in best_configs])\n",
    "    data[:,2] = np.array([c['pp'] for c in best_configs])\n",
    "    df = pd.DataFrame(data,\n",
    "                   index=n_gpus_str,\n",
    "                   columns=[\"data\", \"tensor\", \"pipeline\"])\n",
    "    dfs.append(df)\n",
    "    nvs_str.append(\"nvs = \" + str(nvs))\n",
    "plot_clustered_stacked(dfs, nvs_str, cmap='Pastel2', title='Parallelization configs')\n",
    "# plt.savefig('outputs/par_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9452b-75dd-4455-a2a3-bcef8138e3d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_gpus = 2**np.array([i for i in range(2,14)])\n",
    "n_gpus = [2048]\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "system['nvlink_size'] = 4\n",
    "\n",
    "configs = execute_2d(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=1)\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b0b34-acf1-45ae-a64e-782cad4a4171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_batch_size = 4096\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "\n",
    "nvs_list = [2, 4, 16, 32]\n",
    "verbose = False\n",
    "plots = []\n",
    "\n",
    "for nvs in nvs_list:\n",
    "    t = []\n",
    "    conf = []\n",
    "    start = None\n",
    "    system['nvlink_size'] = nvs\n",
    "    n_gpus = 2**np.array([i for i in range(2,14)])\n",
    "    configs = execute_2d(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=10)\n",
    "    for s,config in enumerate(configs):\n",
    "        if len(config) > 0: # check feasibility\n",
    "            if not start:\n",
    "                start = s\n",
    "            conf.append(config)\n",
    "            t.append([c[0] for c in config])\n",
    "    # print(t)\n",
    "\n",
    "    t_max = [tm[0] for tm in t]\n",
    "    t_min = [tm[-1] for tm in t]\n",
    "    n_gpus = n_gpus[start:]\n",
    "    configs = configs[start:]\n",
    "    \n",
    "    plots.append((nvs, t_max, t_min, n_gpus, configs))\n",
    "np.save('outputs/exec_2d_{}.npy'.format(model_str), np.array(plots, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0905afdc-d1ca-40f1-a3b5-4ae423aa5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_2d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(5,5), tight_layout=True) \n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "for nvs, t_max, t_min, n_gpus, _ in x:\n",
    "    axs.plot(n_gpus, t_max, label='nv = {}'.format(nvs))\n",
    "    axs.fill_between(n_gpus, t_max, t_min, alpha=0.25)\n",
    "    axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Throughput (inputs/sec)', fontsize=14)\n",
    "    axs.set_yticks(2.**np.arange(-1,7))\n",
    "    # axs.set_yticklabels(2.**np.arange(-1,7))\n",
    "axs.legend(fontsize=14)\n",
    "fig.tight_layout()\n",
    "# plt.savefig('outputs/exec_2d_{}.png'.format(model_str), dpi=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ace424-667c-4b76-ac51-7e0c4bccd795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_2d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "dfs = []\n",
    "nvs_str = []\n",
    "for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "    best_configs = [c[0][2] for c in configs]\n",
    "    n_gpus_str = [str(ng) for ng in n_gpus]\n",
    "    parallelization = {\n",
    "        # 'data': np.array([c['dp'] for c in best_configs]),\n",
    "        'tensor1': np.array([c['tp1'] for c in best_configs]),\n",
    "        'tensor2': np.array([c['tp2'] for c in best_configs]),\n",
    "        'pipeline': np.array([c['pp'] for c in best_configs])\n",
    "    }\n",
    "    data = np.zeros((len(n_gpus),len(parallelization)))\n",
    "    idx=-1\n",
    "    # data[:,idx] = np.array([c['dp'] for c in best_configs])\n",
    "    data[:,idx+1] = np.array([c['tp1'] for c in best_configs])\n",
    "    data[:,idx+2] = np.array([c['tp2'] for c in best_configs])\n",
    "    data[:,idx+3] = np.array([c['pp'] for c in best_configs])\n",
    "    df = pd.DataFrame(data,\n",
    "                   index=n_gpus_str,\n",
    "                   columns=[ \"tensor1\", \"tensor2\", \"pipeline\"])\n",
    "    dfs.append(df)\n",
    "    nvs_str.append(\"nvs = \" + str(nvs))\n",
    "plot_clustered_stacked(dfs, nvs_str, cmap='Pastel2', title='Parallelization configs')\n",
    "# plt.savefig('outputs/par_2d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a120c-da13-47f8-aa8d-4ada3c3b4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = [2048]\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "system['nvlink_size'] = 4\n",
    "\n",
    "configs = execute_seqp(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=1)\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8531f0-ea32-47b4-a561-8e74b12a5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 4096\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "\n",
    "nvs_list = [2, 4, 16, 32]\n",
    "verbose = False\n",
    "plots = []\n",
    "\n",
    "for nvs in nvs_list:\n",
    "    t = []\n",
    "    conf = []\n",
    "    start = None\n",
    "    system['nvlink_size'] = nvs\n",
    "    n_gpus = 2**np.array([i for i in range(2,14)])\n",
    "    configs = execute_seqp(model, n_gpus, global_batch_size=global_batch_size, system=system, verbose=False, nlargest=10)\n",
    "    for s,config in enumerate(configs):\n",
    "        if len(config) > 0: # check feasibility\n",
    "            if not start:\n",
    "                start = s\n",
    "            conf.append(config)\n",
    "            t.append([c[0] for c in config])\n",
    "    # print(t)\n",
    "\n",
    "    t_max = [tm[0] for tm in t]\n",
    "    t_min = [tm[-1] for tm in t]\n",
    "    n_gpus = n_gpus[start:]\n",
    "    configs = configs[start:]\n",
    "    \n",
    "    plots.append((nvs, t_max, t_min, n_gpus, configs))\n",
    "np.save('outputs/exec_seqp_{}.npy'.format(model_str), np.array(plots, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080ab2d-af99-4868-9fe1-fa8429a69f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_seqp_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(5,5), tight_layout=True) \n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "for nvs, t_max, t_min, n_gpus, _ in x:\n",
    "    axs.plot(n_gpus, t_max, label='nv = {}'.format(nvs))\n",
    "    axs.fill_between(n_gpus, t_max, t_min, alpha=0.25)\n",
    "    axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Throughput (inputs/sec)', fontsize=14)\n",
    "    axs.set_yticks(2.**np.arange(-1,7))\n",
    "    # axs.set_yticklabels(2.**np.arange(-1,7))\n",
    "axs.legend(fontsize=14)\n",
    "fig.tight_layout()\n",
    "# plt.savefig('outputs/exec_seqp_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852185a-dbcc-4363-8834-acdbaca57563",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_seqp_{}.npy'.format(model_str), allow_pickle=True)\n",
    "dfs = []\n",
    "nvs_str = []\n",
    "for nvs, t_max, t_min, n_gpus, configs in x:\n",
    "    best_configs = [c[0][2] for c in configs]\n",
    "    n_gpus_str = [str(ng) for ng in n_gpus]\n",
    "    parallelization = {\n",
    "        # 'data': np.array([c['dp'] for c in best_configs]),\n",
    "        'tensor1': np.array([c['tp1'] for c in best_configs]),\n",
    "        'tensor2': np.array([c['tp2'] for c in best_configs]),\n",
    "        'pipeline': np.array([c['pp'] for c in best_configs])\n",
    "    }\n",
    "    data = np.zeros((len(n_gpus),len(parallelization)))\n",
    "    idx=-1\n",
    "    # data[:,idx] = np.array([c['dp'] for c in best_configs])\n",
    "    data[:,idx+1] = np.array([c['tp1'] for c in best_configs])\n",
    "    data[:,idx+2] = np.array([c['tp2'] for c in best_configs])\n",
    "    data[:,idx+3] = np.array([c['pp'] for c in best_configs])\n",
    "    df = pd.DataFrame(data,\n",
    "                   index=n_gpus_str,\n",
    "                   columns=[\"tensor1\", \"tensor2\", \"pipeline\"])\n",
    "    dfs.append(df)\n",
    "    nvs_str.append(\"nvs = \" + str(nvs))\n",
    "plot_clustered_stacked(dfs, nvs_str, cmap='Pastel2', title='Parallelization configs')\n",
    "# plt.savefig('outputs/par_seqp_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67331e-d6df-4bc2-a7dc-d0dff618b435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
