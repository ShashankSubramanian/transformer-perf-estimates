{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3876fb2-fec7-43b1-a65a-531fb1e6cedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "from modules import *\n",
    "from execution import *\n",
    "import json\n",
    "import pprint\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef7cacdf-8dbc-4e8e-8ea1-d6e95b1858b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_df(df_mlp, df_sa, verbose=True):\n",
    "    cols = df_mlp.columns.tolist()\n",
    "    layer_track_cols = ['activation_buffer', 'weights_mem', \n",
    "                        'weights_grad_mem', 'flops_fwd', 'flops_bwd', \n",
    "                        't_fwd', 't_fwd_comm', 't_bwd', 't_bwd_comm']\n",
    "    if verbose:\n",
    "        display(df_mlp[cols])\n",
    "        display(df_mlp[layer_track_cols].sum() * depth)\n",
    "        display(df_sa[cols])\n",
    "        display(df_sa[layer_track_cols].sum() * depth)\n",
    "    t_itr = (df_mlp['t_fwd'].sum() + df_mlp['t_bwd'].sum() + df_sa['t_fwd'].sum() + df_sa['t_bwd'].sum()) * depth\n",
    "    print('time for 1 itr = {}'.format(t_itr))\n",
    "\n",
    "    f1 = 3 # 1 fp16 wt, 1 fp32 copy\n",
    "    f2 = 5 # 1 fp16 grad, 2 fp32 means and variances\n",
    "    mem = (df_mlp['weights_mem'].sum() * f1 + df_mlp['weights_grad_mem'].sum() * f2 + df_mlp['activation_buffer'].sum() +\n",
    "           df_sa['weights_mem'].sum() * f1 + df_sa['weights_grad_mem'].sum() * f2 + df_sa['activation_buffer'].sum()) * depth\n",
    "    \n",
    "    flops = (df_mlp['flops_fwd'].sum() + df_mlp['flops_bwd'].sum() \n",
    "             + df_sa['flops_fwd'].sum() + df_sa['flops_bwd'].sum()) * depth\n",
    "    \n",
    "    param_count = ((df_mlp['weights_mem'].sum() + df_sa['weights_mem'].sum()) * depth) / system['element_size']\n",
    "    print('mem consumed = {}'.format(mem))\n",
    "    print('num parameters = {}B'.format(param_count/1E9))\n",
    "    print('total flops = {}TFLOPs'.format(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db844498-37cc-4489-8be3-19d9e04d18a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is {'l': 2048, 'e': 25600, 'h': 160, 'depth': 128, 'f': 102400}\n",
      "training on 488281250.0 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>weights_mem</th>\n",
       "      <th>weights_grad_mem</th>\n",
       "      <th>flops_fwd</th>\n",
       "      <th>activation_buffer</th>\n",
       "      <th>comm_fwd</th>\n",
       "      <th>comm_fwd_type</th>\n",
       "      <th>flops_bwd</th>\n",
       "      <th>comm_bwd</th>\n",
       "      <th>comm_bwd_type</th>\n",
       "      <th>t_fwd</th>\n",
       "      <th>t_fwd_comm</th>\n",
       "      <th>t_fwd_comp</th>\n",
       "      <th>t_fwd_mem</th>\n",
       "      <th>intensity_fwd</th>\n",
       "      <th>t_bwd</th>\n",
       "      <th>t_bwd_comm</th>\n",
       "      <th>t_bwd_comp</th>\n",
       "      <th>t_bwd_mem</th>\n",
       "      <th>intensity_bwd</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fc1</td>\n",
       "      <td>5.242880</td>\n",
       "      <td>5.242880</td>\n",
       "      <td>10.737209</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>21.472163</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.604234</td>\n",
       "      <td>0.086046</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.600320</td>\n",
       "      <td>0.129084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fc1-bias</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.086566</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.086566</td>\n",
       "      <td>0.000540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>act1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.419430</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.078709</td>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dpr1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.209715</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.034643</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.034643</td>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc2</td>\n",
       "      <td>5.242880</td>\n",
       "      <td>5.242880</td>\n",
       "      <td>10.737366</td>\n",
       "      <td>0.419430</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>21.472005</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.604404</td>\n",
       "      <td>0.086046</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.600235</td>\n",
       "      <td>0.129084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fc2-bias</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.308902</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.308902</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dpr2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.052429</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.123621</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.123621</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ln1</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0</td>\n",
       "      <td>allgather</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.204258</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.000472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  weights_mem  weights_grad_mem  flops_fwd  activation_buffer  \\\n",
       "0       fc1     5.242880          5.242880  10.737209           0.104858   \n",
       "1  fc1-bias     0.000205          0.000205   0.000210           0.000000   \n",
       "2      act1     0.000000          0.000000   0.001678           0.419430   \n",
       "3      dpr1     0.000000          0.000000   0.000210           0.209715   \n",
       "4       fc2     5.242880          5.242880  10.737366           0.419430   \n",
       "5  fc2-bias     0.000051          0.000051   0.000052           0.000000   \n",
       "6      dpr2     0.000000          0.000000   0.000052           0.052429   \n",
       "7       ln1     0.000102          0.000102   0.000472           0.104858   \n",
       "\n",
       "   comm_fwd  comm_fwd_type  flops_bwd  comm_bwd  comm_bwd_type     t_fwd  \\\n",
       "0         0  reducescatter  21.472163         0  reducescatter  0.043038   \n",
       "1         0           none   0.000210         0           none  0.000270   \n",
       "2         0           none   0.002726         0           none  0.000539   \n",
       "3         0           none   0.000210         0           none  0.000674   \n",
       "4         0  reducescatter  21.472005         0  reducescatter  0.043038   \n",
       "5         0           none   0.000052         0           none  0.000067   \n",
       "6         0           none   0.000052         0           none  0.000169   \n",
       "7         0      allgather   0.000629         0  reducescatter  0.000135   \n",
       "\n",
       "   t_fwd_comm  t_fwd_comp  t_fwd_mem  intensity_fwd     t_bwd  t_bwd_comm  \\\n",
       "0           0    0.043038   0.000000      11.604234  0.086046           0   \n",
       "1           0    0.000023   0.000247       0.086566  0.000270           0   \n",
       "2           0    0.000047   0.000493       0.086914  0.000809           0   \n",
       "3           0    0.000023   0.000651       0.034643  0.000674           0   \n",
       "4           0    0.043038   0.000000      11.604404  0.086046           0   \n",
       "5           0    0.000021   0.000047       0.308902  0.000067           0   \n",
       "6           0    0.000021   0.000148       0.123621  0.000169           0   \n",
       "7           0    0.000028   0.000107       0.204258  0.000337           0   \n",
       "\n",
       "   t_bwd_comp  t_bwd_mem  intensity_bwd         t  \n",
       "0    0.086046   0.000000      11.600320  0.129084  \n",
       "1    0.000023   0.000247       0.086566  0.000540  \n",
       "2    0.000064   0.000745       0.078709  0.001349  \n",
       "3    0.000023   0.000651       0.034643  0.001349  \n",
       "4    0.086046   0.000000      11.600235  0.129084  \n",
       "5    0.000021   0.000047       0.308902  0.000135  \n",
       "6    0.000021   0.000148       0.123621  0.000337  \n",
       "7    0.000030   0.000307       0.089205  0.000472  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "activation_buffer     167.772160\n",
       "weights_mem          1342.223155\n",
       "weights_grad_mem     1342.223155\n",
       "flops_fwd            2749.087770\n",
       "flops_bwd            5497.350100\n",
       "t_fwd                  11.255115\n",
       "t_fwd_comm              0.000000\n",
       "t_bwd                  22.325582\n",
       "t_bwd_comm              0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>weights_mem</th>\n",
       "      <th>weights_grad_mem</th>\n",
       "      <th>flops_fwd</th>\n",
       "      <th>activation_buffer</th>\n",
       "      <th>comm_fwd</th>\n",
       "      <th>comm_fwd_type</th>\n",
       "      <th>flops_bwd</th>\n",
       "      <th>comm_bwd</th>\n",
       "      <th>comm_bwd_type</th>\n",
       "      <th>t_fwd</th>\n",
       "      <th>t_fwd_comm</th>\n",
       "      <th>t_fwd_comp</th>\n",
       "      <th>t_fwd_mem</th>\n",
       "      <th>intensity_fwd</th>\n",
       "      <th>t_bwd</th>\n",
       "      <th>t_bwd_comm</th>\n",
       "      <th>t_bwd_comp</th>\n",
       "      <th>t_bwd_mem</th>\n",
       "      <th>intensity_bwd</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qkv</td>\n",
       "      <td>3.932160</td>\n",
       "      <td>3.932160</td>\n",
       "      <td>8.052906</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>16.104109</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>0.032283</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.536115</td>\n",
       "      <td>0.064540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.531322</td>\n",
       "      <td>0.096823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fusedla</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439509</td>\n",
       "      <td>0.420741</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>1.096399</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.592056</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.166940</td>\n",
       "      <td>0.006193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vproj</td>\n",
       "      <td>1.310720</td>\n",
       "      <td>1.310720</td>\n",
       "      <td>2.684302</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>5.368001</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.019356</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.007893</td>\n",
       "      <td>0.032301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vproj-bias</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.308902</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.308902</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dpr_v</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.052429</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.123621</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.123621</td>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ln2</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.104858</td>\n",
       "      <td>0</td>\n",
       "      <td>allgather</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0</td>\n",
       "      <td>reducescatter</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.204258</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.000472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  weights_mem  weights_grad_mem  flops_fwd  activation_buffer  \\\n",
       "0         qkv     3.932160          3.932160   8.052906           0.104858   \n",
       "1     fusedla     0.000000          0.000000   0.439509           0.420741   \n",
       "2       vproj     1.310720          1.310720   2.684302           0.104858   \n",
       "3  vproj-bias     0.000051          0.000051   0.000052           0.000000   \n",
       "4       dpr_v     0.000000          0.000000   0.000052           0.052429   \n",
       "5         ln2     0.000102          0.000102   0.000472           0.104858   \n",
       "\n",
       "   comm_fwd  comm_fwd_type  flops_bwd  comm_bwd  comm_bwd_type     t_fwd  \\\n",
       "0         0  reducescatter  16.104109         0  reducescatter  0.032283   \n",
       "1         0           none   1.096399         0           none  0.001781   \n",
       "2         0  reducescatter   5.368001         0  reducescatter  0.010774   \n",
       "3         0           none   0.000052         0           none  0.000067   \n",
       "4         0           none   0.000052         0           none  0.000169   \n",
       "5         0      allgather   0.000629         0  reducescatter  0.000135   \n",
       "\n",
       "   t_fwd_comm  t_fwd_comp  t_fwd_mem  intensity_fwd     t_bwd  t_bwd_comm  \\\n",
       "0           0    0.032283   0.000000      11.536115  0.064540           0   \n",
       "1           0    0.001781   0.000000       6.592056  0.004413           0   \n",
       "2           0    0.010774   0.000000      11.019356  0.021526           0   \n",
       "3           0    0.000021   0.000047       0.308902  0.000067           0   \n",
       "4           0    0.000021   0.000148       0.123621  0.000169           0   \n",
       "5           0    0.000028   0.000107       0.204258  0.000337           0   \n",
       "\n",
       "   t_bwd_comp  t_bwd_mem  intensity_bwd         t  \n",
       "0    0.064540   0.000000      11.531322  0.096823  \n",
       "1    0.004413   0.000000       8.166940  0.006193  \n",
       "2    0.021526   0.000000      11.007893  0.032301  \n",
       "3    0.000021   0.000047       0.308902  0.000135  \n",
       "4    0.000021   0.000148       0.123621  0.000337  \n",
       "5    0.000030   0.000307       0.089205  0.000472  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "activation_buffer     100.831068\n",
       "weights_mem           671.108301\n",
       "weights_grad_mem      671.108301\n",
       "flops_fwd            1430.693704\n",
       "flops_bwd            2888.863118\n",
       "t_fwd                   5.786816\n",
       "t_fwd_comm              0.000000\n",
       "t_bwd                  11.654654\n",
       "t_bwd_comm              0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for 1 itr = 51.02216643073308\n",
      "mem consumed = 16375.254876160001\n",
      "num parameters = 1006.665728B\n",
      "total flops = 12565.994692149246TFLOPs\n"
     ]
    }
   ],
   "source": [
    "model_str = 'gpt3_1T'\n",
    "model = models.models[model_str]\n",
    "# set model hyperparams\n",
    "l = model['l']\n",
    "e = model['e']\n",
    "f = 4 * e\n",
    "model['f'] = f\n",
    "h = model['h']\n",
    "depth = model['depth']\n",
    "print('model is {}'.format(model))\n",
    "\n",
    "# set data hyperparms\n",
    "if model_str == 'gpt3_1T':\n",
    "    total_tokens = 1 * 10**12\n",
    "else:\n",
    "    total_tokens = 300 * 10**9\n",
    "num_samples = total_tokens / l\n",
    "if model_str == 'vit_era5':\n",
    "    num_ep = 80\n",
    "    num_samples = 350000 * num_ep\n",
    "print('training on {} samples'.format(num_samples))\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('systems/config-A100.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "\n",
    "b = 1\n",
    "system['nvlink_size'] = 4\n",
    "m1 = 1\n",
    "t1 = 4\n",
    "df_mlp = mlp_1d(b, l, e, f, parallelism={'m': m1}, topology={'t': t1}, system=system)\n",
    "df_sa = sa_1d(b, l, e, h, parallelism={'m': m1}, topology={'t': t1}, flash_attention=True, system=system)\n",
    "# df_mlp = mlp_seqp(b, l, e, f, parallelism={'m1': m1, 'm2': 1}, topology={'t1': t1, 't2': 1}, system=system)\n",
    "# df_sa = sa_seqp(b, l, e, h, parallelism={'m1': m1, 'm2': 1}, topology={'t1': t1, 't2': 1}, flash_attention=True, system=system)\n",
    "print_df(df_mlp, df_sa, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa074648-a93c-41fc-8f6b-b968995985ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "n_gpus = [128]\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('systems/config-H200.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "system['nvlink_size'] = 4\n",
    "\n",
    "configs = execute_1d(model, n_gpus, global_batch_size=global_batch_size, \n",
    "                     system=system, verbose=False, nlargest=1)\n",
    "\n",
    "# modify througput to times\n",
    "cc = configs#[[((num_samples / c[0]) / (3600 * 24),c[1],c[2],c[3]) for c in cc] for cc in configs]\n",
    "pprint.pprint(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc5f4e-508a-4408-96e9-220dfde94091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mbs = 1\n",
    "tp = 64\n",
    "pp = 8\n",
    "dp = 2\n",
    "nm = (global_batch_size / dp) / mbs\n",
    "print(nm)\n",
    "m1 = tp\n",
    "t1 = 4\n",
    "t_dp = 1\n",
    "t_pp = 1\n",
    "df_mlp = mlp_1d(mbs, l, e, f, parallelism={'m': m1}, topology={'t': t1}, system=system)\n",
    "df_sa = sa_1d(mbs, l, e, h, parallelism={'m': m1}, topology={'t': t1}, flash_attention=True, system=system)\n",
    "df_dp = dataparallel(modules=[df_mlp, df_sa], depth=(depth//pp), dp=dp, t_dp=t_dp, overlap=True, system=system)\n",
    "\n",
    "# pp comms\n",
    "# only communicate the last layer activations = first layer's (ln1) input buffer\n",
    "p2p_comm_vol = float(df_mlp.loc[df_mlp['name'] == 'ln1']['activation_buffer'])\n",
    "df_pp = pipelineparallel(modules=[df_mlp, df_sa], number_micro_batches=nm, comm_vol=p2p_comm_vol, pp=pp, t_pp=t_pp, overlap=False, system=system)\n",
    "\n",
    "# total time\n",
    "(t, mem), stats = totals(df_mlp, df_sa, df_dp, df_pp, depth, pp=pp, dp=dp, number_micro_batches=nm)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad287da-6ef1-464d-82b4-79680c96921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = 'gpt3_1T'\n",
    "model = models.models[model_str]\n",
    "# set model hyperparams\n",
    "l = model['l']\n",
    "e = model['e']\n",
    "f = 4 * e\n",
    "model['f'] = f\n",
    "h = model['h']\n",
    "depth = model['depth']\n",
    "print('model is {}'.format(model))\n",
    "\n",
    "# set data hyperparms\n",
    "if model_str == 'gpt3':\n",
    "    total_tokens = 1 * 10**12\n",
    "else:\n",
    "    total_tokens = 300 * 10**9\n",
    "num_samples = total_tokens / l\n",
    "if model_str == 'vit_era5':\n",
    "    num_ep = 80\n",
    "    num_samples = 350000 * num_ep\n",
    "print('training on {} samples'.format(num_samples))\n",
    "\n",
    "\n",
    "with open('systems/config-B200.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "nvs = 8\n",
    "system['nvlink_size'] = nvs\n",
    "global_batch_size = 4096\n",
    "\n",
    "total_gpus = 4096\n",
    "N = 8\n",
    "n_values = np.arange(0,N)\n",
    "m_values =  [1] * N\n",
    "\n",
    "# tp_values = np.array([16 ,8, 4, 2, 1])\n",
    "# pp_values = np.array([2, 4, 8, 16, 32])\n",
    "# dp_values = (total_gpus / (pp_values * tp_values)).astype(int)\n",
    "\n",
    "\n",
    "tp_values = np.array([4] * N)\n",
    "pp_values = 2**np.arange(0,N) #[1,2,4,8,16,32,64,128]\n",
    "dp_values = (total_gpus / (pp_values * tp_values)).astype(int)\n",
    "\n",
    "# tp_values = 2**np.arange(0,N)\n",
    "# pp_values = np.array([32] * N)\n",
    "# dp_values = (total_gpus / (pp_values * tp_values)).astype(int)\n",
    "# tp_values = 2**np.arange(0,N)\n",
    "# dp_values = np.array([32] * N)\n",
    "# pp_values = (total_gpus / (dp_values * tp_values)).astype(int)\n",
    "\n",
    "print('tp ', tp_values)\n",
    "print('dp ', dp_values)\n",
    "print('pp ', pp_values)\n",
    "print(dp_values * pp_values * tp_values)\n",
    "\n",
    "time_part1 = []\n",
    "time_part2 = []\n",
    "time_part3 = []\n",
    "time_part4 = []\n",
    "time_part5 = []\n",
    "time_part6 = []\n",
    "nm_values = []\n",
    "mem_values = []\n",
    "for mbs,tp,pp,dp in zip(m_values,tp_values,pp_values,dp_values):\n",
    "    best_time = np.inf\n",
    "    best_mem = -np.inf\n",
    "    stats = None\n",
    "    # print(mbs,tp,pp,dp)\n",
    "    for nv1, nv2, nv3 in nv_candidates_1d(tp, dp, pp, nvs):\n",
    "        # print(nv1,nv2,nv3)\n",
    "        nm = (global_batch_size / dp) / mbs\n",
    "        m1 = tp\n",
    "        # t1 = m1 if m1 <= system['nvlink_size'] else system['nvlink_size']\n",
    "        t1 = nv1\n",
    "        t_dp = nv2\n",
    "        t_pp = nv3\n",
    "        df_mlp = mlp_1d(mbs, l, e, f, parallelism={'m': m1}, topology={'t': t1}, system=system)\n",
    "        df_sa = sa_1d(mbs, l, e, h, parallelism={'m': m1}, topology={'t': t1}, flash_attention=True, system=system)\n",
    "        df_dp = dataparallel(modules=[df_mlp, df_sa], depth=(depth//pp), dp=dp, t_dp=t_dp, overlap=True, system=system)\n",
    "\n",
    "        # pp comms\n",
    "        # only communicate the last layer activations = first layer's (ln1) input buffer\n",
    "        p2p_comm_vol = float(df_mlp.loc[df_mlp['name'] == 'ln1']['activation_buffer'])\n",
    "        df_pp = pipelineparallel(modules=[df_mlp, df_sa], number_micro_batches=nm, comm_vol=p2p_comm_vol, pp=pp, t_pp=t_pp, overlap=False, system=system)\n",
    "\n",
    "        # total time\n",
    "        (t, mem), stats_running = totals(df_mlp, df_sa, df_dp, df_pp, depth, pp=pp, dp=dp, number_micro_batches=nm)\n",
    "        stats_running['nv_tp'] = t1\n",
    "        stats_running['nv_dp'] = t_dp\n",
    "        stats_running['nv_pp'] = t_pp\n",
    "        # print(t, stats_running['nv_tp'], stats_running['nv_dp'], stats_running['nv_pp'])\n",
    "        if t < best_time:\n",
    "            stats = stats_running\n",
    "            best_time = t\n",
    "            best_mem = mem\n",
    "    mem_values.append(best_mem)\n",
    "    # print('###')\n",
    "            \n",
    "    print(stats['nv_tp'], stats['nv_dp'], stats['nv_pp'])\n",
    "    time_part1.append(stats['t_comp'])\n",
    "    time_part2.append(stats['t_comm'])\n",
    "    time_part3.append(stats['t_bubble'])\n",
    "    time_part4.append(stats['t_dp_comm'])\n",
    "    time_part5.append(stats['t_mem_exposed'])\n",
    "    time_part6.append(stats['t_pp_comm'])\n",
    "    \n",
    "    nm_values.append(nm)\n",
    "\n",
    "    \n",
    "m_values = nm_values # swap to #microbatches\n",
    "\n",
    "time_part1 = np.array(time_part1)\n",
    "time_part2 = np.array(time_part2)\n",
    "time_part3 = np.array(time_part3)\n",
    "time_part4 = np.array(time_part4)\n",
    "time_part5 = np.array(time_part5)\n",
    "time_part6 = np.array(time_part6)\n",
    "time_total = time_part1 + time_part2 + time_part3 + time_part4 + time_part5 + time_part6\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# First plot: m, tp, dp, pp as a function of n\n",
    "plt.subplot(2, 1, 1)\n",
    "bar_width = 0.2\n",
    "log_n_values = np.array(n_values)\n",
    "\n",
    "plt.bar(log_n_values - 1.5 * bar_width, m_values, bar_width, label='#Microbatches', color='dodgerblue')\n",
    "plt.bar(log_n_values - 0.5 * bar_width, tp_values, bar_width, label='TP', color='salmon')\n",
    "plt.bar(log_n_values + 0.5 * bar_width, dp_values, bar_width, label='DP', color='limegreen')\n",
    "plt.bar(log_n_values + 1.5 * bar_width, pp_values, bar_width, label='PP', color='orange')\n",
    "\n",
    "plt.xlabel('Config', fontsize=16)\n",
    "plt.ylabel('Values', fontsize=16)\n",
    "plt.title('Parallelization Configuration', fontsize=16)\n",
    "plt.xticks(log_n_values, n_values, fontsize=14)\n",
    "plt.yscale('log', base=2)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')\n",
    "top = max(max(m_values), max(tp_values), max(dp_values), max(pp_values))\n",
    "top2 = int(np.ceil(np.log2(top)))+1\n",
    "plt.ylim([0.1, top * 2])\n",
    "plt.yticks([2**i for i in range(0, top2)], [2**i for i in range(0, top2)], fontsize=14)\n",
    "# plt.xlim([np.log2(n_values[0]) - 1, np.log2(n_values[-1]) + 1])\n",
    "plt.legend(fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add mem_values as a twin axis on the right\n",
    "ax3 = plt.gca().twinx()\n",
    "ax3.plot(log_n_values, mem_values, color='black', linewidth=1, linestyle='--', marker='o', label='Memory Usage')\n",
    "ax3.set_ylabel('Memory Usage (in GB)', fontsize=16, color='black')\n",
    "ax3.tick_params(axis='y', labelcolor='black', labelsize=14)\n",
    "ax3.set_ylim(0, 200)\n",
    "\n",
    "# Add legend for the line plot\n",
    "lines, labels = ax3.get_legend_handles_labels()\n",
    "plt.legend(lines, labels, fontsize=12, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Second plot: Time vs n as a stacked bar plot with percentages and total time line\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "bar_width = 0.5\n",
    "\n",
    "# Normalize the time parts\n",
    "time_parts = np.array([time_part1, time_part2, time_part3, time_part4, time_part5, time_part6])\n",
    "time_parts_normalized = time_parts / time_total[:, np.newaxis].T * 100\n",
    "\n",
    "# Create the stacked bar plot\n",
    "colors = ['dodgerblue', 'salmon', 'limegreen', 'orange', 'slateblue', 'skyblue']\n",
    "labels = ['Compute', 'TP Comm', 'PP Bubble', 'DP Comm', 'Memory', 'PP Comm']\n",
    "bottom = np.zeros(len(n_values))\n",
    "\n",
    "for i, (height, color, label) in enumerate(zip(time_parts_normalized, colors, labels)):\n",
    "    p = ax1.bar(log_n_values, height, bottom=bottom, label=label, color=color, width=bar_width)\n",
    "    bottom += height\n",
    "\n",
    "    # Add percentage text\n",
    "    for j, h in enumerate(height):\n",
    "        if h > 1:  # Only show percentage if it's greater than 1%\n",
    "            ax1.text(log_n_values[j], bottom[j] - h/2, f'{h:.1f}%', ha='center', va='center', color='white', fontsize=9)\n",
    "\n",
    "ax1.set_xlabel('Config', fontsize=16)\n",
    "ax1.set_ylabel('Normalized Time (%)', fontsize=16)\n",
    "ax1.set_title('Time', fontsize=16)\n",
    "ax1.set_xticks(log_n_values)\n",
    "ax1.set_xticklabels(n_values, fontsize=14)\n",
    "ax1.set_yticklabels([0,20,40,60,80,100], fontsize=14)\n",
    "ax1.set_yticks([0,20,40,60,80,100])\n",
    "# ax1.set_xlim([np.log2(n_values[0]) - 1, np.log2(n_values[-1]) + 1])\n",
    "ax1.legend(fontsize=12, loc='upper left')\n",
    "ax1.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "# Adjust y-axis to make smaller bars more visible\n",
    "ax1.set_ylim(0, 150)  # Set to slightly over 100% to give some headroom\n",
    "\n",
    "# Add the total time line plot on the right y-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(log_n_values, time_total, color='black', linewidth=1, linestyle='--', marker='o', label='Total Time')\n",
    "ax2.set_ylabel('Time per Iteration (s)', fontsize=16, color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black', labelsize=14)\n",
    "ax2.set_yscale('log', base=2)\n",
    "\n",
    "# Set y-axis limits for total time\n",
    "ax2.set_ylim(min(time_total) / 2, max(time_total) * 2)\n",
    "\n",
    "# Add legend for the line plot\n",
    "lines, labels = ax2.get_legend_handles_labels()\n",
    "ax1.legend(fontsize=12, loc='upper left')\n",
    "ax2.legend(lines, labels, fontsize=12, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48580569-bf7b-4571-bc05-bbd73809b5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
