{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3876fb2-fec7-43b1-a65a-531fb1e6cedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "from modules import *\n",
    "from execution import *\n",
    "import json\n",
    "import pprint\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7cacdf-8dbc-4e8e-8ea1-d6e95b1858b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_df(df_mlp, df_sa, verbose=True):\n",
    "    cols = df_mlp.columns.tolist()\n",
    "    layer_track_cols = ['activation_buffer', 'weights_mem', \n",
    "                        'weights_grad_mem', 'flops_fwd', 'flops_bwd', \n",
    "                        't_fwd', 't_fwd_comm', 't_bwd', 't_bwd_comm']\n",
    "    if verbose:\n",
    "        display(df_mlp[cols])\n",
    "        display(df_mlp[layer_track_cols].sum() * depth)\n",
    "        display(df_sa[cols])\n",
    "        display(df_sa[layer_track_cols].sum() * depth)\n",
    "    t_itr = (df_mlp['t_fwd'].sum() + df_mlp['t_bwd'].sum() + df_sa['t_fwd'].sum() + df_sa['t_bwd'].sum()) * depth\n",
    "    print('time for 1 itr = {}'.format(t_itr))\n",
    "\n",
    "    f1 = 3 # 1 fp16 wt, 1 fp32 copy\n",
    "    f2 = 5 # 1 fp16 grad, 2 fp32 means and variances\n",
    "    mem = (df_mlp['weights_mem'].sum() * f1 + df_mlp['weights_grad_mem'].sum() * f2 + df_mlp['activation_buffer'].sum() +\n",
    "           df_sa['weights_mem'].sum() * f1 + df_sa['weights_grad_mem'].sum() * f2 + df_sa['activation_buffer'].sum()) * depth\n",
    "    \n",
    "    flops = (df_mlp['flops_fwd'].sum() + df_mlp['flops_bwd'].sum() \n",
    "             + df_sa['flops_fwd'].sum() + df_sa['flops_bwd'].sum()) * depth\n",
    "    \n",
    "    param_count = ((df_mlp['weights_mem'].sum() + df_sa['weights_mem'].sum()) * depth) / system['element_size']\n",
    "    print('mem consumed = {}'.format(mem))\n",
    "    print('num parameters = {}B'.format(param_count/1E9))\n",
    "    print('total flops = {}TFLOPs'.format(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db844498-37cc-4489-8be3-19d9e04d18a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_str = 'gpt3_1T'\n",
    "model = models.models[model_str]\n",
    "# set model hyperparams\n",
    "l = model['l']\n",
    "e = model['e']\n",
    "f = 4 * e\n",
    "model['f'] = f\n",
    "h = model['h']\n",
    "depth = model['depth']\n",
    "print('model is {}'.format(model))\n",
    "\n",
    "# set data hyperparms\n",
    "if model_str == 'gpt3_1T':\n",
    "    total_tokens = 1 * 10**12\n",
    "else:\n",
    "    total_tokens = 300 * 10**9\n",
    "num_samples = total_tokens / l\n",
    "if model_str == 'vit_era5':\n",
    "    num_ep = 80\n",
    "    num_samples = 350000 * num_ep\n",
    "print('training on {} samples'.format(num_samples))\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('systems/config-A100.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "\n",
    "b = 1\n",
    "system['nvlink_size'] = 4\n",
    "m1 = 1\n",
    "t1 = 4\n",
    "df_mlp = mlp_1d(b, l, e, f, parallelism={'m': m1}, topology={'t': t1}, system=system)\n",
    "df_sa = sa_1d(b, l, e, h, parallelism={'m': m1}, topology={'t': t1}, flash_attention=True, system=system)\n",
    "# df_mlp = mlp_seqp(b, l, e, f, parallelism={'m1': m1, 'm2': 1}, topology={'t1': t1, 't2': 1}, system=system)\n",
    "# df_sa = sa_seqp(b, l, e, h, parallelism={'m1': m1, 'm2': 1}, topology={'t1': t1, 't2': 1}, flash_attention=True, system=system)\n",
    "print_df(df_mlp, df_sa, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa074648-a93c-41fc-8f6b-b968995985ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_gpus = [128]\n",
    "global_batch_size = 4096\n",
    "\n",
    "with open('systems/config-H200.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "system['nvlink_size'] = 4\n",
    "\n",
    "configs = execute_1d(model, n_gpus, global_batch_size=global_batch_size, \n",
    "                     system=system, verbose=False, nlargest=1)\n",
    "\n",
    "# modify througput to times\n",
    "cc = configs#[[((num_samples / c[0]) / (3600 * 24),c[1],c[2],c[3]) for c in cc] for cc in configs]\n",
    "pprint.pprint(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc5f4e-508a-4408-96e9-220dfde94091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mbs = 1\n",
    "tp = 64\n",
    "pp = 8\n",
    "dp = 2\n",
    "nm = (global_batch_size / dp) / mbs\n",
    "print(nm)\n",
    "m1 = tp\n",
    "t1 = 4\n",
    "t_dp = 1\n",
    "t_pp = 1\n",
    "df_mlp = mlp_1d(mbs, l, e, f, parallelism={'m': m1}, topology={'t': t1}, system=system)\n",
    "df_sa = sa_1d(mbs, l, e, h, parallelism={'m': m1}, topology={'t': t1}, flash_attention=True, system=system)\n",
    "df_dp = dataparallel(modules=[df_mlp, df_sa], depth=(depth//pp), dp=dp, t_dp=t_dp, overlap=True, system=system)\n",
    "\n",
    "# pp comms\n",
    "# only communicate the last layer activations = first layer's (ln1) input buffer\n",
    "p2p_comm_vol = float(df_mlp.loc[df_mlp['name'] == 'ln1']['activation_buffer'])\n",
    "df_pp = pipelineparallel(modules=[df_mlp, df_sa], number_micro_batches=nm, comm_vol=p2p_comm_vol, pp=pp, t_pp=t_pp, overlap=False, system=system)\n",
    "\n",
    "# total time\n",
    "(t, mem), stats = totals(df_mlp, df_sa, df_dp, df_pp, depth, pp=pp, dp=dp, number_micro_batches=nm)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad287da-6ef1-464d-82b4-79680c96921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = 'gpt3_1T'\n",
    "model = models.models[model_str]\n",
    "# set model hyperparams\n",
    "l = model['l']\n",
    "e = model['e']\n",
    "f = 4 * e\n",
    "model['f'] = f\n",
    "h = model['h']\n",
    "depth = model['depth']\n",
    "print('model is {}'.format(model))\n",
    "\n",
    "# set data hyperparms\n",
    "if model_str == 'gpt3':\n",
    "    total_tokens = 1 * 10**12\n",
    "else:\n",
    "    total_tokens = 300 * 10**9\n",
    "num_samples = total_tokens / l\n",
    "if model_str == 'vit_era5':\n",
    "    num_ep = 80\n",
    "    num_samples = 350000 * num_ep\n",
    "print('training on {} samples'.format(num_samples))\n",
    "\n",
    "\n",
    "with open('systems/config-B200.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "nvs = 8\n",
    "system['nvlink_size'] = nvs\n",
    "global_batch_size = 4096\n",
    "\n",
    "total_gpus = 4096\n",
    "N = 8\n",
    "n_values = np.arange(0,N)\n",
    "m_values =  [1] * N\n",
    "\n",
    "# tp_values = np.array([16 ,8, 4, 2, 1])\n",
    "# pp_values = np.array([2, 4, 8, 16, 32])\n",
    "# dp_values = (total_gpus / (pp_values * tp_values)).astype(int)\n",
    "\n",
    "\n",
    "tp_values = np.array([4] * N)\n",
    "pp_values = 2**np.arange(0,N) #[1,2,4,8,16,32,64,128]\n",
    "dp_values = (total_gpus / (pp_values * tp_values)).astype(int)\n",
    "\n",
    "# tp_values = 2**np.arange(0,N)\n",
    "# pp_values = np.array([32] * N)\n",
    "# dp_values = (total_gpus / (pp_values * tp_values)).astype(int)\n",
    "# tp_values = 2**np.arange(0,N)\n",
    "# dp_values = np.array([32] * N)\n",
    "# pp_values = (total_gpus / (dp_values * tp_values)).astype(int)\n",
    "\n",
    "print('tp ', tp_values)\n",
    "print('dp ', dp_values)\n",
    "print('pp ', pp_values)\n",
    "print(dp_values * pp_values * tp_values)\n",
    "\n",
    "time_part1 = []\n",
    "time_part2 = []\n",
    "time_part3 = []\n",
    "time_part4 = []\n",
    "time_part5 = []\n",
    "time_part6 = []\n",
    "nm_values = []\n",
    "mem_values = []\n",
    "for mbs,tp,pp,dp in zip(m_values,tp_values,pp_values,dp_values):\n",
    "    best_time = np.inf\n",
    "    best_mem = -np.inf\n",
    "    stats = None\n",
    "    # print(mbs,tp,pp,dp)\n",
    "    for nv1, nv2, nv3 in nv_candidates_1d(tp, dp, pp, nvs):\n",
    "        # print(nv1,nv2,nv3)\n",
    "        nm = (global_batch_size / dp) / mbs\n",
    "        m1 = tp\n",
    "        # t1 = m1 if m1 <= system['nvlink_size'] else system['nvlink_size']\n",
    "        t1 = nv1\n",
    "        t_dp = nv2\n",
    "        t_pp = nv3\n",
    "        df_mlp = mlp_1d(mbs, l, e, f, parallelism={'m': m1}, topology={'t': t1}, system=system)\n",
    "        df_sa = sa_1d(mbs, l, e, h, parallelism={'m': m1}, topology={'t': t1}, flash_attention=True, system=system)\n",
    "        df_dp = dataparallel(modules=[df_mlp, df_sa], depth=(depth//pp), dp=dp, t_dp=t_dp, overlap=True, system=system)\n",
    "\n",
    "        # pp comms\n",
    "        # only communicate the last layer activations = first layer's (ln1) input buffer\n",
    "        p2p_comm_vol = float(df_mlp.loc[df_mlp['name'] == 'ln1']['activation_buffer'])\n",
    "        df_pp = pipelineparallel(modules=[df_mlp, df_sa], number_micro_batches=nm, comm_vol=p2p_comm_vol, pp=pp, t_pp=t_pp, overlap=False, system=system)\n",
    "\n",
    "        # total time\n",
    "        (t, mem), stats_running = totals(df_mlp, df_sa, df_dp, df_pp, depth, pp=pp, dp=dp, number_micro_batches=nm)\n",
    "        stats_running['nv_tp'] = t1\n",
    "        stats_running['nv_dp'] = t_dp\n",
    "        stats_running['nv_pp'] = t_pp\n",
    "        # print(t, stats_running['nv_tp'], stats_running['nv_dp'], stats_running['nv_pp'])\n",
    "        if t < best_time:\n",
    "            stats = stats_running\n",
    "            best_time = t\n",
    "            best_mem = mem\n",
    "    mem_values.append(best_mem)\n",
    "    # print('###')\n",
    "            \n",
    "    print(stats['nv_tp'], stats['nv_dp'], stats['nv_pp'])\n",
    "    time_part1.append(stats['t_comp'])\n",
    "    time_part2.append(stats['t_comm'])\n",
    "    time_part3.append(stats['t_bubble'])\n",
    "    time_part4.append(stats['t_dp_comm'])\n",
    "    time_part5.append(stats['t_mem_exposed'])\n",
    "    time_part6.append(stats['t_pp_comm'])\n",
    "    \n",
    "    nm_values.append(nm)\n",
    "\n",
    "    \n",
    "m_values = nm_values # swap to #microbatches\n",
    "\n",
    "time_part1 = np.array(time_part1)\n",
    "time_part2 = np.array(time_part2)\n",
    "time_part3 = np.array(time_part3)\n",
    "time_part4 = np.array(time_part4)\n",
    "time_part5 = np.array(time_part5)\n",
    "time_part6 = np.array(time_part6)\n",
    "time_total = time_part1 + time_part2 + time_part3 + time_part4 + time_part5 + time_part6\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# First plot: m, tp, dp, pp as a function of n\n",
    "plt.subplot(2, 1, 1)\n",
    "bar_width = 0.2\n",
    "log_n_values = np.array(n_values)\n",
    "\n",
    "plt.bar(log_n_values - 1.5 * bar_width, m_values, bar_width, label='#Microbatches', color='dodgerblue')\n",
    "plt.bar(log_n_values - 0.5 * bar_width, tp_values, bar_width, label='TP', color='salmon')\n",
    "plt.bar(log_n_values + 0.5 * bar_width, dp_values, bar_width, label='DP', color='limegreen')\n",
    "plt.bar(log_n_values + 1.5 * bar_width, pp_values, bar_width, label='PP', color='orange')\n",
    "\n",
    "plt.xlabel('Config', fontsize=16)\n",
    "plt.ylabel('Values', fontsize=16)\n",
    "plt.title('Parallelization Configuration', fontsize=16)\n",
    "plt.xticks(log_n_values, n_values, fontsize=14)\n",
    "plt.yscale('log', base=2)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')\n",
    "top = max(max(m_values), max(tp_values), max(dp_values), max(pp_values))\n",
    "top2 = int(np.ceil(np.log2(top)))+1\n",
    "plt.ylim([0.1, top * 2])\n",
    "plt.yticks([2**i for i in range(0, top2)], [2**i for i in range(0, top2)], fontsize=14)\n",
    "# plt.xlim([np.log2(n_values[0]) - 1, np.log2(n_values[-1]) + 1])\n",
    "plt.legend(fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add mem_values as a twin axis on the right\n",
    "ax3 = plt.gca().twinx()\n",
    "ax3.plot(log_n_values, mem_values, color='black', linewidth=1, linestyle='--', marker='o', label='Memory Usage')\n",
    "ax3.set_ylabel('Memory Usage (in GB)', fontsize=16, color='black')\n",
    "ax3.tick_params(axis='y', labelcolor='black', labelsize=14)\n",
    "ax3.set_ylim(0, 200)\n",
    "\n",
    "# Add legend for the line plot\n",
    "lines, labels = ax3.get_legend_handles_labels()\n",
    "plt.legend(lines, labels, fontsize=12, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Second plot: Time vs n as a stacked bar plot with percentages and total time line\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "bar_width = 0.5\n",
    "\n",
    "# Normalize the time parts\n",
    "time_parts = np.array([time_part1, time_part2, time_part3, time_part4, time_part5, time_part6])\n",
    "time_parts_normalized = time_parts / time_total[:, np.newaxis].T * 100\n",
    "\n",
    "# Create the stacked bar plot\n",
    "colors = ['dodgerblue', 'salmon', 'limegreen', 'orange', 'slateblue', 'skyblue']\n",
    "labels = ['Compute', 'TP Comm', 'PP Bubble', 'DP Comm', 'Memory', 'PP Comm']\n",
    "bottom = np.zeros(len(n_values))\n",
    "\n",
    "for i, (height, color, label) in enumerate(zip(time_parts_normalized, colors, labels)):\n",
    "    p = ax1.bar(log_n_values, height, bottom=bottom, label=label, color=color, width=bar_width)\n",
    "    bottom += height\n",
    "\n",
    "    # Add percentage text\n",
    "    for j, h in enumerate(height):\n",
    "        if h > 1:  # Only show percentage if it's greater than 1%\n",
    "            ax1.text(log_n_values[j], bottom[j] - h/2, f'{h:.1f}%', ha='center', va='center', color='white', fontsize=9)\n",
    "\n",
    "ax1.set_xlabel('Config', fontsize=16)\n",
    "ax1.set_ylabel('Normalized Time (%)', fontsize=16)\n",
    "ax1.set_title('Time', fontsize=16)\n",
    "ax1.set_xticks(log_n_values)\n",
    "ax1.set_xticklabels(n_values, fontsize=14)\n",
    "ax1.set_yticklabels([0,20,40,60,80,100], fontsize=14)\n",
    "ax1.set_yticks([0,20,40,60,80,100])\n",
    "# ax1.set_xlim([np.log2(n_values[0]) - 1, np.log2(n_values[-1]) + 1])\n",
    "ax1.legend(fontsize=12, loc='upper left')\n",
    "ax1.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "# Adjust y-axis to make smaller bars more visible\n",
    "ax1.set_ylim(0, 150)  # Set to slightly over 100% to give some headroom\n",
    "\n",
    "# Add the total time line plot on the right y-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(log_n_values, time_total, color='black', linewidth=1, linestyle='--', marker='o', label='Total Time')\n",
    "ax2.set_ylabel('Time per Iteration (s)', fontsize=16, color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black', labelsize=14)\n",
    "ax2.set_yscale('log', base=2)\n",
    "\n",
    "# Set y-axis limits for total time\n",
    "ax2.set_ylim(min(time_total) / 2, max(time_total) * 2)\n",
    "\n",
    "# Add legend for the line plot\n",
    "lines, labels = ax2.get_legend_handles_labels()\n",
    "ax1.legend(fontsize=12, loc='upper left')\n",
    "ax2.legend(lines, labels, fontsize=12, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48580569-bf7b-4571-bc05-bbd73809b5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
