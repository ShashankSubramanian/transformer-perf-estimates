{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3876fb2-fec7-43b1-a65a-531fb1e6cedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "from modules import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2b0c4-dd59-453b-bd85-fa200178727c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt2 = {'l': 1024, 'e': 1600, 'h': 32, 'depth': 48}\n",
    "gpt3 = {'l': 2048, 'e': 12288, 'h': 96, 'depth': 96}\n",
    "gpt3_1T = {'l': 2048, 'e': 25600, 'h': 160, 'depth': 180}\n",
    "gpt3_lowdepth = {'l': 2048, 'e': 12288, 'h': 96, 'depth': 96 // 8}\n",
    "vit_era5 = {'l': 64800, 'e': 5120, 'h': 256, 'depth': 24}\n",
    "vit_era5_big = {'l': 64800, 'e': 6144, 'h': 32, 'depth': 32}\n",
    "### model\n",
    "model = gpt3_1T\n",
    "b = 1\n",
    "l = model['l']\n",
    "e = model['e']\n",
    "f = 4 * e\n",
    "h = model['h']\n",
    "depth = model['depth']\n",
    "print(\"model: batch size = {}, seq length = {}, embed = {}, attention heads = {}, depth = {}\".format(b, l, e, h, depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975b965-53f2-41be-a7d3-947cf8963f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d334d2-483f-4b28-88f6-1118d2a34778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_df(df_mlp, df_sa):\n",
    "    cols = df_mlp.columns.tolist()\n",
    "    layer_track_cols = ['activation_buffer', 'weights_mem', \n",
    "                        'weights_grad_mem', 'flops_fwd', 'flops_bwd', \n",
    "                        't_fwd', 't_fwd_comm', 't_bwd', 't_bwd_comm']\n",
    "    display(df_mlp[cols])\n",
    "    display(df_mlp[layer_track_cols].sum() * depth)\n",
    "    display(df_sa[cols])\n",
    "    display(df_sa[layer_track_cols].sum() * depth)\n",
    "    t_itr = (df_mlp['t_fwd'].sum() + df_mlp['t_bwd'].sum() + df_sa['t_fwd'].sum() + df_sa['t_bwd'].sum()) * depth\n",
    "    print('time for 1 itr = {}'.format(t_itr))\n",
    "\n",
    "    f1 = 3 # 1 fp16 wt, 1 fp32 copy\n",
    "    f2 = 5 # 1 fp16 grad, 2 fp32 means and variances\n",
    "    mem = (df_mlp['weights_mem'].sum() * f1 + df_mlp['weights_grad_mem'].sum() * f2 + df_mlp['activation_buffer'].sum() +\n",
    "           df_sa['weights_mem'].sum() * f1 + df_sa['weights_grad_mem'].sum() * f2 + df_sa['activation_buffer'].sum()) * depth\n",
    "    print('mem consumed = {}'.format(mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db844498-37cc-4489-8be3-19d9e04d18a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1 = 32\n",
    "system['nvlink_size'] = 4\n",
    "t1 = m1 if m1 <= system['nvlink_size'] else system['nvlink_size']\n",
    "df_mlp = mlp_1d(b, l, e, f, parallelism={'m': m1}, topology={'t': t1}, system=system)\n",
    "df_sa = sa_1d(b, l, e, h, parallelism={'m': m1}, topology={'t': t1}, flash_attention=True, system=system)\n",
    "print_df(df_mlp, df_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3ea4a-b396-4d7a-9a3e-2427c20df5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = 4\n",
    "m2 = 4\n",
    "t1 = 4\n",
    "t2 = 1\n",
    "system['nvlink_size'] = 4\n",
    "system['summa_nb'] = 16\n",
    "df_mlp = mlp_2d(b, l, e, f, parallelism={'m1': m1, 'm2': m2}, topology={'t1': t1, 't2': t2}, system=system)\n",
    "df_sa = sa_2d_seqp(b, l, e, h, parallelism={'m1': m1, 'm2': m2}, topology={'t1': t1, 't2': t2}, flash_attention=True, system=system)\n",
    "print_df(df_mlp, df_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479dd03-ca44-44e1-92d8-574cb6133504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(n_gpus, system, axs, lgnd=['MLP', 'SA'], lgnd_tot=['nvlink1'], lfmt=\"-\"):\n",
    "    t_mlp = []\n",
    "    t_sa = []\n",
    "    t_itr = []\n",
    "\n",
    "    for n in n_gpus:\n",
    "        m1 = n\n",
    "        t1 = m1 if m1 <= system['nvlink_size'] else system['nvlink_size']\n",
    "        \n",
    "        df_mlp = mlp_1d(b, l, e, f, parallelism={'m': m1}, topology={'t': t1}, system=system)\n",
    "        df_sa = sa_1d(b, l, e, h, parallelism={'m': m1}, topology={'t': t1}, flash_attention=True, system=system)\n",
    "\n",
    "        t_mlp_ = (df_mlp['t_fwd'].sum() + df_mlp['t_bwd'].sum()) * depth\n",
    "        t_sa_ = (df_sa['t_fwd'].sum() + df_sa['t_bwd'].sum()) * depth\n",
    "        t_itr.append(t_mlp_ + t_sa_)\n",
    "        t_mlp.append(t_mlp_)\n",
    "        t_sa.append(t_sa_)\n",
    "\n",
    "    \n",
    "    ax = axs[0]\n",
    "    ax.plot(n_gpus, t_mlp, lfmt, linewidth=2, c=c1)\n",
    "    ax.plot(n_gpus, t_sa, lfmt, linewidth=2, c=c2)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.set_xlabel('Number of GPUs', fontsize=fsz)\n",
    "    ax.set_xticks(n_gpus)\n",
    "    ax.set_xticklabels(n_gpus, fontsize=fsz-4)\n",
    "    ax.set_ylabel('Time', fontsize=fsz)    \n",
    "    ax.legend(lgnd, fontsize=fsz-4)\n",
    "    \n",
    "    ax = axs[1]\n",
    "    ax.plot(n_gpus, t_itr, lfmt, linewidth=2)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.set_xlabel('Number of GPUs', fontsize=fsz)\n",
    "    ax.set_xticks(n_gpus)\n",
    "    ax.set_xticklabels(n_gpus, fontsize=fsz-4)\n",
    "    ax.set_ylabel('Total time', fontsize=fsz)\n",
    "    ax.legend(lgnd_tot, fontsize=fsz-4)\n",
    "    ax.yaxis.set_minor_formatter(FormatStrFormatter(\"%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a2695-0156-4447-9646-4ce6649a320d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sweeps\n",
    "### model parallelism\n",
    "n_gpus = [1, 4, 8, 16, 32, 64, 128]\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,5), tight_layout=True) \n",
    "c1 = 'steelblue'\n",
    "c2 = 'salmon'\n",
    "fsz = 18\n",
    "\n",
    "nvs = 4\n",
    "system['nvlink_size'] = nvs\n",
    "lgnd = [\"MLP-nvlink{}\".format(nvs), \"SA-nvlink{}\".format(nvs)]\n",
    "lgnd_tot = [\"nvlink{}\".format(nvs)]\n",
    "plot(n_gpus, system, axs, lgnd=lgnd, lgnd_tot=lgnd_tot, lfmt=\"o-\")\n",
    "nvs = 16\n",
    "system['nvlink_size'] = nvs\n",
    "lgnd += [\"MLP-nvlink{}\".format(nvs), \"SA-nvlink{}\".format(nvs)]\n",
    "lgnd_tot += [\"nvlink{}\".format(nvs)]\n",
    "plot(n_gpus, system, axs, lgnd=lgnd, lgnd_tot=lgnd_tot, lfmt=\"*:\")\n",
    "nvs = 2\n",
    "system['nvlink_size'] = nvs\n",
    "lgnd += [\"MLP-nvlink{}\".format(nvs), \"SA-nvlink{}\".format(nvs)]\n",
    "lgnd_tot += [\"nvlink{}\".format(nvs)]\n",
    "plot(n_gpus, system, axs, lgnd=lgnd, lgnd_tot=lgnd_tot, lfmt=\"o--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89600358-81f4-4357-8a61-891f4c29b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gpus(n, nvs):\n",
    "    parallelism = {}\n",
    "    topology = {}\n",
    "    factors_of_n = [[i, n//i] for i in range(1, int(n**0.5) + 1) if n % i == 0]\n",
    "    best_factor = factors_of_n[-1]\n",
    "    parallelism['m1'] = best_factor[0]\n",
    "    parallelism['m2'] = best_factor[1]\n",
    "    \n",
    "    m1 = parallelism['m1'] \n",
    "    m2 = parallelism['m2'] \n",
    "    topology['t1'] = m1 if m1 <= system['nvlink_size'] else system['nvlink_size']\n",
    "    topology['t2'] = 1\n",
    "        \n",
    "    # print(parallelism, topology)\n",
    "    return parallelism, topology\n",
    "\n",
    "def plot_2d(n_gpus, system, axs, lgnd=['MLP', 'SA'], lgnd_tot=['nvlink1'], lfmt=\"-\"):\n",
    "    t_mlp = []\n",
    "    t_sa = []\n",
    "    t_itr = []\n",
    "\n",
    "    for n in n_gpus:\n",
    "        parallelism, topology = set_gpus(n, system['nvlink_size'])\n",
    "        \n",
    "        df_mlp = mlp_2d(b, l, e, f, parallelism=parallelism, topology=topology, system=system)\n",
    "        df_sa = sa_2d_seqp(b, l, e, h, parallelism=parallelism, topology=topology, flash_attention=True, system=system)\n",
    "        # df_sa = sa_2d(b, l, e, h, parallelism=parallelism, topology=topology, system=system)\n",
    "\n",
    "        t_mlp_ = (df_mlp['t_fwd'].sum() + df_mlp['t_bwd'].sum()) * depth\n",
    "        t_sa_ = (df_sa['t_fwd'].sum() + df_sa['t_bwd'].sum()) * depth\n",
    "        t_itr.append(t_mlp_ + t_sa_)\n",
    "        t_mlp.append(t_mlp_)\n",
    "        t_sa.append(t_sa_)\n",
    "\n",
    "    \n",
    "    ax = axs[0]\n",
    "    ax.plot(n_gpus, t_mlp, lfmt, linewidth=2, c=c1)\n",
    "    ax.plot(n_gpus, t_sa, lfmt, linewidth=2, c=c2)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.set_xlabel('Number of GPUs', fontsize=fsz)\n",
    "    ax.set_xticks(n_gpus)\n",
    "    ax.set_xticklabels(n_gpus, fontsize=fsz-4)\n",
    "    ax.set_ylabel('Time', fontsize=fsz)    \n",
    "    ax.legend(lgnd, fontsize=fsz-4)\n",
    "    \n",
    "    ax = axs[1]\n",
    "    ax.plot(n_gpus, t_itr, lfmt, linewidth=2)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.set_xlabel('Number of GPUs', fontsize=fsz)\n",
    "    ax.set_xticks(n_gpus)\n",
    "    ax.set_xticklabels(n_gpus, fontsize=fsz-4)\n",
    "    ax.set_ylabel('Total time', fontsize=fsz)\n",
    "    ax.legend(lgnd_tot, fontsize=fsz-4)\n",
    "    ax.yaxis.set_minor_formatter(FormatStrFormatter(\"%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2ef48-c1e9-49de-8f1e-a0a3424b27de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sweeps\n",
    "### model parallelism\n",
    "n_gpus = [1, 4, 16, 36, 64, 100, 144]\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,5), tight_layout=True) \n",
    "c1 = 'steelblue'\n",
    "c2 = 'salmon'\n",
    "fsz = 18\n",
    "system['summa_nb'] = 4\n",
    "lgnd = []\n",
    "lgnd_tot = []\n",
    "nvs = 4\n",
    "system['nvlink_size'] = nvs\n",
    "lgnd = [\"MLP-nvlink{}\".format(nvs), \"SA-nvlink{}\".format(nvs)]\n",
    "lgnd_tot = [\"nvlink{}\".format(nvs)]\n",
    "plot_2d(n_gpus, system, axs, lgnd=lgnd, lgnd_tot=lgnd_tot, lfmt=\"o-\")\n",
    "nvs = 16\n",
    "system['nvlink_size'] = nvs\n",
    "lgnd += [\"MLP-nvlink{}\".format(nvs), \"SA-nvlink{}\".format(nvs)]\n",
    "lgnd_tot += [\"nvlink{}\".format(nvs)]\n",
    "plot_2d(n_gpus, system, axs, lgnd=lgnd, lgnd_tot=lgnd_tot, lfmt=\"*:\")\n",
    "nvs = 2\n",
    "system['nvlink_size'] = nvs\n",
    "lgnd += [\"MLP-nvlink{}\".format(nvs), \"SA-nvlink{}\".format(nvs)]\n",
    "lgnd_tot += [\"nvlink{}\".format(nvs)]\n",
    "plot_2d(n_gpus, system, axs, lgnd=lgnd, lgnd_tot=lgnd_tot, lfmt=\"o--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d3858-52d1-4f70-8028-ae0b411a3fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007087ed-9369-4258-bc3e-26ce4073bcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
