{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f398280-8212-4cdd-b8a8-b50dd2b31ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "from modules import *\n",
    "from execution import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952cad8-da0b-4d28-805d-0c67261a626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = {'l': 1024, 'e': 1600, 'h': 32, 'depth': 48}\n",
    "gpt3 = {'l': 2048, 'e': 12288, 'h': 96, 'depth': 96}\n",
    "gpt3_1T = {'l': 2048, 'e': 25600, 'h': 160, 'depth': 180}\n",
    "gpt3_lowdepth = {'l': 2048, 'e': 12288, 'h': 256, 'depth': 96 // 8}\n",
    "vit_era5 = {'l': 64800, 'e': 5120, 'h': 32, 'depth': 24}\n",
    "vit_era5_big = {'l': 64800, 'e': 6144, 'h': 32, 'depth': 32}\n",
    "vit_era5_1px = {'l': 1036800, 'e': 6144, 'h': 32, 'depth': 32}\n",
    "vit_era5_1px_big = {'l': 1036800, 'e': 12288, 'h': 96, 'depth': 96}\n",
    "### model\n",
    "model = vit_era5_big\n",
    "model_str = 'vit_era5_big'\n",
    "# model = vit_era5_1px\n",
    "global_batch = 1024\n",
    "l = model['l']\n",
    "e = model['e']\n",
    "f = 4 * e\n",
    "model['f'] = f\n",
    "h = model['h']\n",
    "depth = model['depth']\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ccdee6-eaf0-4577-8da8-b43a9e0ff226",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 4096\n",
    "with open('config.json', 'r') as file:\n",
    "    system = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b6a2a-f700-4364-8a61-6226652b0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(7,4), tight_layout=True) \n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "counter=0\n",
    "for nvs, th_max, th_min, tc_max, tc_min, int_max, int_min, mem_max, \\\n",
    "                  mem_min, acts_min, acts_max, cfwd_max, cfwd_min, cbwd_max, cbwd_min, \\\n",
    "                  flops_max, flops_min, dps_max, dps_min, tps_max, tps_min, pps_max, pps_min, n_gpus in x:\n",
    "    axs.plot(n_gpus, th_max, label='nv = {}'.format(nvs),color='C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_max)/np.array(dps_max)), label='nv = {}'.format(nvs), color = 'C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_min)/np.array(dps_min)), linestyle='--', color = 'C'+str(counter))\n",
    "    axs.fill_between(n_gpus, th_min,th_max, alpha=0.25)\n",
    "    # print(np.array(t_max) - np.array(t_min))\n",
    "    axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Throughput (inputs/sec)', fontsize=14)\n",
    "    axs.set_yticks(2.**np.arange(-2,8))\n",
    "    counter+=1\n",
    "axs.legend(fontsize=12,ncols=2)\n",
    "fig.tight_layout()\n",
    "# plt.savefig('outputs/exec_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90532431-5073-44f9-b320-c64d165802dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(7,4), tight_layout=True) \n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "counter=0\n",
    "for nvs, th_max, th_min, tc_max, tc_min, int_max, int_min, mem_max, \\\n",
    "                  mem_min, acts_min, acts_max, cfwd_max, cfwd_min, cbwd_max, cbwd_min, \\\n",
    "                  flops_max, flops_min, dps_max, dps_min, tps_max, tps_min, pps_max, pps_min, n_gpus in x:\n",
    "    axs.plot(n_gpus, np.array(cfwd_max), label='nv = {}'.format(nvs),color='C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_max)/np.array(dps_max)), label='nv = {}'.format(nvs), color = 'C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_min)/np.array(dps_min)), linestyle='--', color = 'C'+str(counter))\n",
    "    # axs.fill_between(n_gpus, cfwd_min, cfwd_max, alpha=0.25)\n",
    "    # print(np.array(t_max) - np.array(t_min))\n",
    "    # axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Message size per GPU (GB)', fontsize=14)\n",
    "    # axs.set_yticks(2.**np.arange(-2,8))\n",
    "    axs.set_ylim(0,2)\n",
    "    counter+=1\n",
    "axs.legend(fontsize=12,ncols=2)\n",
    "fig.tight_layout()\n",
    "# plt.savefig('outputs/exec_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36966de-1578-40ce-b852-8b1b90e63618",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(7,4), tight_layout=True) \n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "counter=0\n",
    "for nvs, th_max, th_min, tc_max, tc_min, int_max, int_min, mem_max, \\\n",
    "                  mem_min, acts_min, acts_max, cfwd_max, cfwd_min, cbwd_max, cbwd_min, \\\n",
    "                  flops_max, flops_min, dps_max, dps_min, tps_max, tps_min, pps_max, pps_min, n_gpus in x:\n",
    "    axs.plot(n_gpus, np.array(mem_max), label='nv = {}'.format(nvs),color='C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_max)/np.array(dps_max)), label='nv = {}'.format(nvs), color = 'C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_min)/np.array(dps_min)), linestyle='--', color = 'C'+str(counter))\n",
    "    axs.fill_between(n_gpus, mem_min, mem_max, alpha=0.25)\n",
    "    # print(np.array(t_max) - np.array(t_min))\n",
    "    # axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Memory per GPU (GB)', fontsize=14)\n",
    "    # axs.set_yticks(2.**np.arange(-2,8))\n",
    "    axs.set_ylim(0,100)\n",
    "    counter+=1\n",
    "axs.legend(fontsize=12,ncols=2)\n",
    "fig.tight_layout()\n",
    "# plt.savefig('outputs/exec_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ea855-0e3d-4400-96f9-573217025109",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(7,4), tight_layout=True) \n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "counter=0\n",
    "for nvs, th_max, th_min, tc_max, tc_min, int_max, int_min, mem_max, \\\n",
    "                  mem_min, acts_min, acts_max, cfwd_max, cfwd_min, cbwd_max, cbwd_min, \\\n",
    "                  flops_max, flops_min, dps_max, dps_min, tps_max, tps_min, pps_max, pps_min, n_gpus in x:\n",
    "    axs.plot(n_gpus, np.array(dps_max), label='nv = {}'.format(nvs),color='C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_max)/np.array(dps_max)), label='nv = {}'.format(nvs), color = 'C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_min)/np.array(dps_min)), linestyle='--', color = 'C'+str(counter))\n",
    "    # axs.fill_between(n_gpus, cfwd_min, cfwd_max, alpha=0.25)\n",
    "    # print(np.array(t_max) - np.array(t_min))\n",
    "    # axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Tensor Parallelism', fontsize=14)\n",
    "    # axs.set_yticks(2.**np.arange(-2,8))\n",
    "    # axs.set_ylim(0,40)\n",
    "    counter+=1\n",
    "axs.legend(fontsize=12,ncols=2)\n",
    "fig.tight_layout()\n",
    "# plt.savefig('outputs/exec_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c5dff-5224-4367-bd43-0e225c18849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "fig, axs = plt.subplots(1,1,figsize=(7,4), tight_layout=True) \n",
    "axs.tick_params(axis='both', which='major', labelsize=12)\n",
    "axs.tick_params(axis='both', which='minor', labelsize=12)\n",
    "counter=0\n",
    "for nvs, th_max, th_min, tc_max, tc_min, int_max, int_min, mem_max, \\\n",
    "                  mem_min, acts_min, acts_max, cfwd_max, cfwd_min, cbwd_max, cbwd_min, \\\n",
    "                  flops_max, flops_min, dps_max, dps_min, tps_max, tps_min, pps_max, pps_min, n_gpus in x:\n",
    "    axs.plot(n_gpus, np.array(pps_max), label='nv = {}'.format(nvs),color='C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_max)/np.array(dps_max)), label='nv = {}'.format(nvs), color = 'C'+str(counter))\n",
    "    # axs.plot(n_gpus, (4096/np.array(tps_min)/np.array(dps_min)), linestyle='--', color = 'C'+str(counter))\n",
    "    # axs.fill_between(n_gpus, cfwd_min, cfwd_max, alpha=0.25)\n",
    "    # print(np.array(t_max) - np.array(t_min))\n",
    "    # axs.set_yscale('log', base=2)\n",
    "    axs.set_xscale('log', base=2)\n",
    "    axs.set_xticks(n_gpus)\n",
    "    axs.set_xticklabels(n_gpus)\n",
    "    axs.set_xlabel('Number of GPUs', fontsize=14)\n",
    "    axs.set_ylabel('Pipeline Parallelism', fontsize=14)\n",
    "    # axs.set_yticks(2.**np.arange(-2,8))\n",
    "    axs.set_ylim(0,10)\n",
    "    counter+=1\n",
    "axs.legend(fontsize=12,ncols=2)\n",
    "fig.tight_layout()\n",
    "# plt.savefig('outputs/exec_1d_{}.png'.format(model_str), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d46dd1-9503-4d55-914f-41c473cc537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('outputs/exec_1d_{}.npy'.format(model_str), allow_pickle=True)\n",
    "for nvs, th_max, th_min, tc_max, tc_min, int_max, int_min, mem_max, \\\n",
    "                  mem_min, acts_min, acts_max, cfwd_max, cfwd_min, cbwd_max, cbwd_min, \\\n",
    "                  flops_max, flops_min, dps_max, dps_min, tps_max, tps_min, pps_max, pps_min, n_gpus in x:\n",
    "    np.array(dps_max)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb35db1-d819-4fb8-a81a-2a1d54d69659",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d7e4f05-5425-4b39-8cb3-8f9cb1d32e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "gpt2 = {'l': 1024, 'e': 1600, 'h': 32, 'depth': 48}\n",
    "gpt3 = {'l': 2048, 'e': 12288, 'h': 96, 'depth': 96}\n",
    "gpt3_1T = {'l': 2048, 'e': 25600, 'h': 160, 'depth': 180}\n",
    "gpt3_lowdepth = {'l': 2048, 'e': 12288, 'h': 256, 'depth': 96 // 8}\n",
    "vit_era5 = {'l': 64800, 'e': 5120, 'h': 32, 'depth': 24}\n",
    "vit_era5_big = {'l': 64800, 'e': 6144, 'h': 32, 'depth': 32}\n",
    "vit_era5_1px = {'l': 1036800, 'e': 6144, 'h': 32, 'depth': 32}\n",
    "vit_era5_1px_big = {'l': 1036800, 'e': 12288, 'h': 96, 'depth': 96}\n",
    "\n",
    "models= {'gpt2': gpt2, 'gpt3': gpt3, 'gpt3_1T': gpt3_1T, 'gpt3_lowdepth': gpt3_lowdepth, \\\n",
    "         'vit_era5': vit_era5, 'vit_era5_big': vit_era5_big, 'vit_era5_1px': vit_era5_1px, 'vit_era5_1px_big': vit_era5_1px_big}\n",
    "\n",
    "\n",
    "\n",
    "def compute_stats(global_batch_size,config_type,n_gpus,nvs_list,model, model_str, exec_model,nlargest,verbose):\n",
    "    if exec_model == '1d':\n",
    "        execute_function = execute_1d\n",
    "    elif exec_model == '2d':\n",
    "        execute_function = execute_2d\n",
    "        \n",
    "    with open('config-'+config_type+'.json', 'r') as file:\n",
    "        system = json.load(file)\n",
    "        \n",
    "    throughputs = {}\n",
    "    stats = {}\n",
    "    confs = {}\n",
    "    ngpus={}\n",
    "\n",
    "    start = None\n",
    "    \n",
    "    for nvs in nvs_list:\n",
    "        throughputs[nvs] = {}\n",
    "        stats[nvs] = {}\n",
    "        confs[nvs] = {}\n",
    "        start = None\n",
    "        system['nvlink_size'] = nvs\n",
    "    \n",
    "        configs = execute_function(model, n_gpus, global_batch_size=global_batch_size, \\\n",
    "                                   system=system, verbose=verbose, nlargest=nlargest)\n",
    "        ngpus[nvs]=sorted(configs.keys())\n",
    "      \n",
    "        \n",
    "        for n in ngpus[nvs]:\n",
    "            throughputs[nvs][n]=[]\n",
    "            stats[nvs][n]=[]\n",
    "            confs[nvs][n]=[]\n",
    "            for conf in configs[n]:\n",
    "                throughputs[nvs][n].append(conf[0])\n",
    "                stats[nvs][n].append(conf[1])\n",
    "                confs[nvs][n].append(conf[3])\n",
    "    return confs, stats, throughputs,ngpus\n",
    "            \n",
    "#         return configs[0]\n",
    "#         ngpus[nvs]=n_gpusf\n",
    "#         for s,config in enumerate(configs):\n",
    "#             if len(config) > 0: # check feasibility\n",
    "#                 if not start:\n",
    "#                     start = s\n",
    "#                 return config,n_gpusf\n",
    "#                 return 0\n",
    "#                 throughput, stat, _, conf = config[0]\n",
    "\n",
    "#                 \n",
    "#                 stats[nvs].append(stat)\n",
    "#                 confs[nvs].append(conf)\n",
    "\n",
    "#         n_gpus = n_gpus[start:]\n",
    "        \n",
    "#     np.savez('outputs/exec_'+exec_model+'_model_'+str(model_str)+'_config_'+config_type+'.npz', \\\n",
    "#          confs=confs, stats=stats, throughputs = throughputs, ngpus=ngpus, global_batch_size=global_batch_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46b39751",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = 2**np.array([i for i in range(2,14)])\n",
    "nvs_list = list(2**np.array([i for i in range(1,7)]))\n",
    "model = models['gpt3_1T']\n",
    "model['f'] = 4 * model['e']\n",
    "tst1,tst2,tst3,tst4=compute_stats(4096,'A100',n_gpus,nvs_list,model, 'gpt3_1T', '1d',10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3045d736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7378a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 8, 16, 32, 64]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fefec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
